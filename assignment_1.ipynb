{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Making Under Uncertainty - Assignment 1\n",
    "\n",
    "Group 2:\n",
    "- Martijn Ketelaars (ANR: 120975)\n",
    "- Robbie Reyerse (ANR: 109997)\n",
    "- Rosalien Timmerhuis (ANR: 520618)\n",
    "- Mike Weltevrede (ANR: 756479)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import itertools\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gurobipy as gb\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "num_instances = 10\n",
    "num_items = 10\n",
    "g = 2 # group number\n",
    "alpha_model = {\"EV\": 0, \"CVaR\": 0.95}\n",
    "beta_model = {\"EV\": 0, \"CVaR\": 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of Problem Instances\n",
    "## Part 1\n",
    "In the first part, we want to generate 10 random instances of the Stochastic Knapsack Problem (SKP). For this, we need to generate values for the low weights using the Poisson distribution. From Lab 2, we know that the `numpy.random` library is the fastest in doing this. For the high weights, we will use the same library, using the `triangular()` function from `numpy.random`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_instance(num_items, g, seed):\n",
    "    \"\"\"Generate a dictionary of `num_items` possible item sizes\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_items : int\n",
    "        Number of items to generate weights for\n",
    "    g : int\n",
    "        Group number\n",
    "    seed : int\n",
    "        Random seed\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    item_sizes : dict\n",
    "        Dictionary containing the possible item sizes\n",
    "    \"\"\"\n",
    "\n",
    "    # Assert inputs are of correct form\n",
    "    assert isinstance(num_items, int), \"num_items is not an int\"\n",
    "    assert isinstance(g, int), \"g is not an int\"\n",
    "    assert isinstance(seed, int), \"seed is not an int\"\n",
    "\n",
    "    # Generate possible item sizes.\n",
    "    np.random.seed(seed)\n",
    "    lam = [math.ceil((i + 1)/2) for i in range(num_items)]\n",
    "    dl = np.minimum(np.random.poisson(lam), 10)\n",
    "    dh = [np.random.triangular(90 + g - (i+1), 100 + g - (i+1), 110 + g - (i+1))\n",
    "          for i in range(num_items)]\n",
    "\n",
    "    item_sizes = {\"dl\": dl, \"dh\": dh}\n",
    "\n",
    "    return item_sizes\n",
    "\n",
    "\n",
    "def skp(num_instances, num_items, g):\n",
    "    \"\"\"Generates `num_instances` instances of a Stochastic Knapsack Problem (SKP).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_instances : int\n",
    "        Number of instances of the SKP to generate\n",
    "    num_items : int\n",
    "        Number of items to consider per instance\n",
    "    g : int\n",
    "        Group number\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    instance : tuple\n",
    "        Tuple containing the unit excess weight penalty `p`, knapsack capacity `K`, item size\n",
    "        probability vector `pi`, revenue vector `r`, and possible item sizes `item_sizes`,\n",
    "        respectively.\n",
    "    \"\"\"\n",
    "\n",
    "    # Assert inputs are of correct form\n",
    "    assert isinstance(num_instances, int), \"num_instances is not an int\"\n",
    "    assert isinstance(num_items, int), \"num_items is not an int\"\n",
    "    assert isinstance(g, int), \"g is not an int\"\n",
    "\n",
    "    # Generate instance variables\n",
    "    p = math.floor(60 + 0.1 * g)  # Unit excess weight penalty\n",
    "    K = 400 + 4 * g  # Knapsack capacity\n",
    "\n",
    "    pi = np.asarray([0.5 + 0.05 * (i + 1) - 0.001 for i in range(num_items)])  # Item size probabilities\n",
    "    r = np.asarray([51 - (i + 1) for i in range(num_items)])  # Revenues\n",
    "\n",
    "    item_sizes = {j: generate_instance(num_items, g, seed=j) for j in range(num_instances)}  # dl, dh\n",
    "\n",
    "    instance = (p, K, pi, r, item_sizes)\n",
    "\n",
    "    return instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.549 0.599 0.649 0.699 0.749 0.799 0.849 0.899 0.949 0.999]\n"
     ]
    }
   ],
   "source": [
    "p, K, pi, r, item_sizes = skp(num_instances, num_items, g)\n",
    "print(pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heuristic Algorithm\n",
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_algorithm(problem_instance, pi, r, item_sizes, K):\n",
    "    \"\"\"Generates a selection vector for an SKP based on a greedy approach.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    problem_instance : int\n",
    "        Integer indicating which instance to take\n",
    "    pi : list\n",
    "        List of probabilities whether an item will attain a high weight\n",
    "    g : int\n",
    "        Group number\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    instance : tuple\n",
    "        Tuple containing the unit excess weight penalty `p`, knapsack capacity `K`, item size\n",
    "        probability vector `pi`, revenue vector `r`, and possible item sizes `item_sizes`,\n",
    "        respectively.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute expectation of w_i for each item\n",
    "    Ew = item_sizes[problem_instance][\"dh\"] * np.array(pi) + item_sizes[problem_instance][\"dl\"] * (np.array(1) - pi)\n",
    "        \n",
    "    sorted_expected_revenue = np.argsort(r)[::-1]\n",
    "\n",
    "    # Initialise zero-value x and W\n",
    "    x = np.zeros(10, dtype=np.int16)\n",
    "    W = 0\n",
    "\n",
    "    while len(sorted_expected_revenue) != 0:\n",
    "\n",
    "        consider_item = sorted_expected_revenue[0]\n",
    "\n",
    "        if W + Ew[consider_item] <= K:\n",
    "            x[consider_item] = 1\n",
    "            W = W + Ew[consider_item]\n",
    "\n",
    "        sorted_expected_revenue = np.delete(sorted_expected_revenue, 0)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Simulation\n",
    "## Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [1 1 1 1 1 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "problem_instance = 0\n",
    "x = greedy_algorithm(problem_instance, pi, r, item_sizes, K)\n",
    "print(\"x:\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_profits(item_sizes, x, r, pi, num_items, num_runs, problem_instance):\n",
    "\n",
    "    profits = []\n",
    "\n",
    "    for run in range(num_runs):\n",
    "        u = np.random.uniform(size=num_items)\n",
    "        w = [item_sizes[problem_instance][\"dh\"][i] if u[i] < pi[i] else item_sizes[problem_instance][\"dl\"][i]\n",
    "            for i in range(num_items)]\n",
    "        w = np.asarray(w)\n",
    "\n",
    "        total_weight = np.dot(x, w)\n",
    "        excess = max(total_weight-K, 0)\n",
    "\n",
    "        profit = np.dot(x, r*w) - excess*p\n",
    "        profits.append(profit)\n",
    "\n",
    "    profits = sorted(profits)\n",
    "\n",
    "    return profits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to calculate the optimal number of runs for running our Monte Carlo simulation. For this, we need to first get an estimate for the standard deviation of the distribution of the profits...\n",
    "\n",
    "### Note: look at np.std function again. I think we're not doing it correctly formula for np.std that Python uses is\n",
    "\\begin{align*}\n",
    "            \\hat{\\sigma} = (\\frac{1}{M} \\sum_{j =1}^M (X_j - \\bar{X})^2)^{\\frac{1}{2}}.\n",
    "    \\end{align*}\n",
    "\n",
    "### but we need \n",
    "\\begin{align*}\n",
    "            \\hat{\\sigma} = \\left ( \\frac{1}{M(M-1)} \\sum_{j =1}^M (X_j - \\bar{X})^2 \\right )^{\\frac{1}{2}}.\n",
    "    \\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma: 2992.8778947247874\n"
     ]
    }
   ],
   "source": [
    "# Calculate number of runs; first a test run to get an estimate for sigma\n",
    "profits = calculate_profits(item_sizes, x, r, pi, num_items, num_runs=1000, problem_instance=problem_instance)\n",
    "sigma = np.std(profits) \n",
    "print(\"sigma:\", sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'd like to show the distribution of the profits. Due to the jumps between selecting a certain number of high and low weights, the distribution looks highly irregular. As such, results may not necessarily be reliable. Nonetheless, as advised by the lecturer, we still take the approach as discussed in the first few lectures. \n",
    "\n",
    "(Perhaps better to replace this section by a plot of the distribution of the sample mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15ed9fc6668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(profits, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then select a value for `alpha` equal to 0.05 as the confidence level for our preferred half-width, defined by `epsilon`. This then gives us the desired number of runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 9366\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "z = stats.norm.ppf(1-alpha/2)\n",
    "\n",
    "epsilon = 0.01*np.mean(profits) # half-width\n",
    "n = int(np.ceil((z*sigma/epsilon)**2))\n",
    "print(\"n:\", n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we find the profits for this number of runs `n` and the corresponding confidence interval for the sample mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'calculate_profits' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-116-c7260adbfad0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Now find profits for this number of runs...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprofits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculate_profits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_items\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_runs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproblem_instance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mproblem_instance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# and find the confidence interval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mhalf_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msigma\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'calculate_profits' is not defined"
     ]
    }
   ],
   "source": [
    "# Now find profits for this number of runs...\n",
    "profits = calculate_profits(item_sizes, x, r, pi, num_items, num_runs=n, problem_instance=problem_instance)\n",
    "\n",
    "# and find the confidence interval\n",
    "half_width = z*sigma/math.sqrt(n)\n",
    "confidence_interval = (np.mean(profits) - half_width, np.mean(profits) + half_width)\n",
    "print(\"Confidence interval:\", confidence_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Programming Models\n",
    "## Part 4.\n",
    "\n",
    "The model: \n",
    "\\begin{align*}\n",
    "    \\max_{x, \\varepsilon_u,\\eta, S_u } \\; (1-\\beta) \\left [ \\sum_{u \\in U} P_u \\left ( \\sum_{i=1}^{10} r_i w_{iu} x_i - p \\varepsilon_u \\right ) \\right ] + \\beta \\left [ \\eta - \\frac{1}{1-\\alpha} \\sum_{u \\in U } P_u S_u \\right ]\n",
    "\\end{align*}\n",
    "subject to \n",
    "\\begin{align*}\n",
    "    \\begin{aligned}\n",
    "     x_i & \\in \\{0,1\\} & \\quad & \\text{ for all } i \\in I \\\\\n",
    "     \\varepsilon_u & \\geq 0 & \\quad & \\text{ for all } u \\in U \\\\\n",
    "    \\varepsilon_u & \\geq \\sum_{i=1} ^{10} w_{iu} x_i - K  & \\quad &  \\text{ for all } u \\in U \\\\\n",
    "    S_u & \\geq 0 & \\quad & \\text{ for all } u \\in U \\\\\n",
    "    S_u & \\geq \\eta - \\left ( \\sum_{i=1}^{10} r_i w_{iu} x_i - p \\varepsilon_u \\right ) & \\quad & \\text{ for all } u \\in U.\n",
    "\\end{aligned}\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For testing purposes\n",
    "scenario1 = [item_sizes[problem_instance]['dh'][i] if (i % 2 == 0) else item_sizes[problem_instance]['dl'][i] for i in range(num_items)]\n",
    "scenario2 = [item_sizes[problem_instance]['dl'][i] if (i % 2 == 0) else item_sizes[problem_instance]['dh'][i] for i in range(num_items)]\n",
    "scenario3 = [item_sizes[problem_instance]['dl'][i] if i <= 4 else item_sizes[problem_instance]['dh'][i] for i in range(num_items)]\n",
    "\n",
    "scenario_weights = (scenario1, scenario2, scenario3)\n",
    "scenario_probabilities = (1/3, 1/3, 1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Create all 1024 scenarios ####\n",
    "# Binary scenarios creates all possible permutations of 0 and 1\n",
    "def create_scenarios(problem_instance):\n",
    "    binary_scenarios = [list(i) for i in itertools.product([0, 1], repeat=num_items)]\n",
    "\n",
    "    # We will, without loss of generality, define that a 1 in binary_scenarios corresponds with a high weight\n",
    "    scenario_weights = [[item_sizes[problem_instance]['dh'][i] if scenario[i] == 1\n",
    "                         else item_sizes[problem_instance]['dl'][i]\n",
    "                         for i in range(num_items)]\n",
    "                        for scenario in binary_scenarios]\n",
    "    scenario_probabilities = [np.prod([pi[i] if scenario[i] == 1 else (1-pi[i])\n",
    "                                       for i in range(num_items)])\n",
    "                              for scenario in binary_scenarios]\n",
    "    \n",
    "    return scenario_weights, scenario_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model formulation in Gurobi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gurobi_optimization(problem_instance,beta,alpha,r,p,K):\n",
    "\n",
    "    # Generate scenarios for problem instance\n",
    "    scenario_weights, scenario_probabilities = create_scenarios(problem_instance)\n",
    "    \n",
    "    # Misc\n",
    "    items = range(num_items)\n",
    "    scenarios = range(len(scenario_weights))\n",
    "\n",
    "    if beta == 0:\n",
    "        alpha = alpha[\"EV\"]\n",
    "    else:\n",
    "        alpha = alpha[\"CVaR\"]\n",
    "    \n",
    "    # Create empty model\n",
    "    m = gb.Model()\n",
    "    m.setParam('OutputFlag', 0)\n",
    "    # Create variables \n",
    "    x = m.addVars(items, vtype=gb.GRB.BINARY, name= \"x\")\n",
    "    eta = m.addVars(1, vtype=gb.GRB.CONTINUOUS, name=\"eta\")\n",
    "    epsilon = m.addVars(scenarios, vtype=gb.GRB.CONTINUOUS, name=\"epsilon\", lb=0) \n",
    "    s = m.addVars(scenarios, vtype=gb.GRB.CONTINUOUS, name=\"s\", lb=0)\n",
    "\n",
    "    # Set objective function\n",
    "    def scenario_profit(scenario):\n",
    "        return gb.quicksum(r[item]*scenario_weights[scenario][item]*x[item]-p*epsilon[scenario] for item in items)\n",
    "\n",
    "    obj_1 = (1-beta)*gb.quicksum(scenario_probabilities[scenario]*scenario_profit(scenario) for scenario in scenarios)\n",
    "    obj_2 = beta*(eta[0]-(1/(1-alpha))*gb.quicksum(scenario_probabilities[scenario]*s[scenario] for scenario in scenarios))\n",
    "\n",
    "    m.setObjective(obj_1 + obj_2, gb.GRB.MAXIMIZE)\n",
    "\n",
    "    # # Create constraints\n",
    "    # Epsilon constraint\n",
    "    for scenario in scenarios:\n",
    "        m.addConstr(epsilon[scenario] >= gb.quicksum(scenario_weights[scenario][item]*x[item] for item in items) - K)\n",
    "\n",
    "    # S constraint\n",
    "    for scenario in scenarios:\n",
    "        m.addConstr(s[scenario] >= eta[0] - scenario_profit(scenario))\n",
    "\n",
    "    # Solve model\n",
    "    m.optimize()\n",
    "    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Solve EV model\n",
    "model_solves_EV = [gurobi_optimization(instance,beta_model[\"EV\"],alpha_model,r,p,K) for instance in range(num_instances)]\n",
    "# model_solves_EV = gurobi_optimization(0,beta_model[\"EV\"],alpha_model[\"EV\"],r,p,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Solve CVaR mode\n",
    "model_solves_CVaR = [gurobi_optimization(instance, beta_model[\"CVaR\"], alpha_model, r, p, K) for instance in range(num_instances)]\n",
    "# model_solves_CVaR = gurobi_optimization(0, beta_model[\"EV\"], alpha_model[\"CVaR\"], r, p, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for instance 1\n",
      "Maximum objective value:  14629.374682536607\n",
      "EV   | x: [0, 0, 0, 1, 0, 0, 0, 1, 1, 1] | eta: [0]\n",
      "\n",
      "Maximum objective value:  9689.949901109063\n",
      "CVar | x: [0, 0, 0, 0, 0, 0, 1, 1, 1, 1] | eta: [11661]\n",
      "\n",
      "Result for instance 2\n",
      "Maximum objective value:  15339.808183792346\n",
      "EV   | x: [0, 0, 0, 0, 0, 1, 0, 1, 1, 1] | eta: [0]\n",
      "\n",
      "Maximum objective value:  10031.358582811823\n",
      "CVar | x: [0, 0, 0, 0, 0, 0, 1, 1, 1, 1] | eta: [12107]\n",
      "\n",
      "Result for instance 3\n",
      "Maximum objective value:  15039.997476211218\n",
      "EV   | x: [0, 0, 0, 0, 0, 1, 0, 1, 1, 1] | eta: [0]\n",
      "\n",
      "Maximum objective value:  9769.45455698534\n",
      "CVar | x: [0, 0, 0, 0, 0, 0, 1, 1, 1, 1] | eta: [11899]\n",
      "\n",
      "Result for instance 4\n",
      "Maximum objective value:  14310.844199467268\n",
      "EV   | x: [0, 0, 0, 0, 0, 0, 1, 1, 1, 1] | eta: [0]\n",
      "\n",
      "Maximum objective value:  9537.581366271468\n",
      "CVar | x: [0, 0, 0, 0, 0, 0, 1, 1, 1, 1] | eta: [11531]\n",
      "\n",
      "Result for instance 5\n",
      "Maximum objective value:  14983.208156931087\n",
      "EV   | x: [0, 0, 0, 0, 0, 1, 0, 1, 1, 1] | eta: [0]\n",
      "\n",
      "Maximum objective value:  10017.138190795282\n",
      "CVar | x: [0, 0, 0, 0, 0, 0, 1, 1, 1, 1] | eta: [12067]\n",
      "\n",
      "Result for instance 6\n",
      "Maximum objective value:  15165.953109446551\n",
      "EV   | x: [0, 0, 0, 0, 1, 0, 1, 1, 1, 0] | eta: [0]\n",
      "\n",
      "Maximum objective value:  9782.886236389264\n",
      "CVar | x: [0, 0, 0, 0, 0, 0, 1, 1, 1, 1] | eta: [12022]\n",
      "\n",
      "Result for instance 7\n",
      "Maximum objective value:  14800.399643524042\n",
      "EV   | x: [0, 0, 0, 0, 0, 0, 1, 1, 1, 1] | eta: [0]\n",
      "\n",
      "Maximum objective value:  10004.31202581941\n",
      "CVar | x: [0, 0, 0, 0, 0, 0, 1, 1, 1, 1] | eta: [11965]\n",
      "\n",
      "Result for instance 8\n",
      "Maximum objective value:  14883.297388857127\n",
      "EV   | x: [0, 0, 0, 0, 0, 1, 0, 1, 1, 1] | eta: [0]\n",
      "\n",
      "Maximum objective value:  9848.560387322892\n",
      "CVar | x: [0, 0, 0, 0, 0, 0, 1, 1, 1, 1] | eta: [11937]\n",
      "\n",
      "Result for instance 9\n",
      "Maximum objective value:  14315.632511645856\n",
      "EV   | x: [0, 0, 0, 0, 0, 1, 0, 1, 1, 1] | eta: [0]\n",
      "\n",
      "Maximum objective value:  9526.20373012833\n",
      "CVar | x: [0, 0, 0, 0, 0, 0, 1, 1, 1, 1] | eta: [11573]\n",
      "\n",
      "Result for instance 10\n",
      "Maximum objective value:  14637.122332257759\n",
      "EV   | x: [0, 0, 0, 0, 1, 0, 1, 1, 1, 0] | eta: [0]\n",
      "\n",
      "Maximum objective value:  9609.247220716265\n",
      "CVar | x: [0, 0, 0, 0, 0, 0, 1, 1, 1, 1] | eta: [11579]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    for j in range(num_instances):\n",
    "        v_EV = model_solves_EV[j].getVars()\n",
    "        v_CVaR = model_solves_CVaR[j].getVars()\n",
    "\n",
    "        outcome_x_EV = [int(v_EV[i].x) for i in range(len(v_EV)) if (re.sub(\"\\[\\d+\\]\", \"\", v_EV[i].varName) == \"x\")]\n",
    "        outcome_eta_EV = [int(v_EV[i].x) for i in range(len(v_EV)) if (re.sub(\"\\[\\d+\\]\", \"\", v_EV[i].varName) == \"eta\")]\n",
    "        outcome_epsilon_EV = [int(v_EV[i].x) for i in range(len(v_EV)) if (re.sub(\"\\[\\d+\\]\", \"\", v_EV[i].varName) == \"epsilon\")]\n",
    "        outcome_s_EV = [int(v_EV[i].x) for i in range(len(v_EV)) if (re.sub(\"\\[\\d+\\]\", \"\", v_EV[i].varName) == \"s\")]\n",
    "\n",
    "        outcome_x_CVaR = [int(v_CVaR[i].x) for i in range(len(v_CVaR)) if (re.sub(\"\\[\\d+\\]\", \"\", v_CVaR[i].varName) == \"x\")]\n",
    "        outcome_eta_CVaR = [int(v_CVaR[i].x) for i in range(len(v_CVaR)) if (re.sub(\"\\[\\d+\\]\", \"\", v_CVaR[i].varName) == \"eta\")]\n",
    "        outcome_epsilon_CVaR = [int(v_CVaR[i].x) for i in range(len(v_CVaR)) if (re.sub(\"\\[\\d+\\]\", \"\", v_CVaR[i].varName) == \"epsilon\")]\n",
    "        outcome_s_CVaR = [int(v_CVaR[i].x) for i in range(len(v_CVaR)) if (re.sub(\"\\[\\d+\\]\", \"\", v_CVaR[i].varName) == \"s\")]\n",
    "\n",
    "        print(\"Result for instance\", j+1)\n",
    "        print(\"Maximum objective value: \", model_solves_EV[j].Objval)\n",
    "        print(\"EV   | x:\", outcome_x_EV, \"| eta:\", outcome_eta_EV)\n",
    "        print(\"\")\n",
    "        print(\"Maximum objective value: \", model_solves_CVaR[j].Objval)\n",
    "        print(\"CVar | x:\", outcome_x_CVaR, \"| eta:\", outcome_eta_CVaR)\n",
    "        print(\"\")\n",
    "except TypeError:\n",
    "    v_EV = model_solves_EV.getVars()\n",
    "    v_CVaR = model_solves_CVaR.getVars()\n",
    "\n",
    "    outcome_x_EV = [int(v_EV[i].x) for i in range(len(v_EV)) if (re.sub(\"\\[\\d+\\]\", \"\", v_EV[i].varName) == \"x\")]\n",
    "    outcome_eta_EV = [int(v_EV[i].x) for i in range(len(v_EV)) if (re.sub(\"\\[\\d+\\]\", \"\", v_EV[i].varName) == \"eta\")]\n",
    "    outcome_epsilon_EV = [int(v_EV[i].x) for i in range(len(v_EV)) if (re.sub(\"\\[\\d+\\]\", \"\", v_EV[i].varName) == \"epsilon\")]\n",
    "    outcome_s_EV = [int(v_EV[i].x) for i in range(len(v_EV)) if (re.sub(\"\\[\\d+\\]\", \"\", v_EV[i].varName) == \"s\")]\n",
    "\n",
    "    outcome_x_CVaR = [int(v_CVaR[i].x) for i in range(len(v_CVaR)) if (re.sub(\"\\[\\d+\\]\", \"\", v_CVaR[i].varName) == \"x\")]\n",
    "    outcome_eta_CVaR = [int(v_CVaR[i].x) for i in range(len(v_CVaR)) if (re.sub(\"\\[\\d+\\]\", \"\", v_CVaR[i].varName) == \"eta\")]\n",
    "    outcome_epsilon_CVaR = [int(v_CVaR[i].x) for i in range(len(v_CVaR)) if (re.sub(\"\\[\\d+\\]\", \"\", v_CVaR[i].varName) == \"epsilon\")]\n",
    "    outcome_s_CVaR = [int(v_CVaR[i].x) for i in range(len(v_CVaR)) if (re.sub(\"\\[\\d+\\]\", \"\", v_CVaR[i].varName) == \"s\")]\n",
    "\n",
    "    print(\"Maximum objective value: \", model_solves_EV.Objval)\n",
    "    print(\"EV   | x:\", outcome_x_EV, \"| eta:\", outcome_eta_EV)\n",
    "    print(\"\")\n",
    "    print(\"Maximum objective value: \", model_solves_CVaR.Objval)\n",
    "    print(\"CVar | x:\", outcome_x_CVaR, \"| eta:\", outcome_eta_CVaR)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Average Approximation\n",
    "## Part 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate a random sample of $W^1, W^2, \\dots, W^N$ of the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateWeights(pi,num_items,item_sizes,problem_instance):\n",
    "    V = np.random.uniform(size=num_items)\n",
    "    W = [item_sizes[problem_instance][\"dh\"][i] if V[i] < pi[i] else item_sizes[problem_instance][\"dl\"][i] \n",
    "        for i in range(num_items)]\n",
    "    W = np.asarray(W)\n",
    "    return W\n",
    "\n",
    "def generateScenarios_SAA(pi,num_items,item_sizes,problem_instance,N):\n",
    "    return [generateWeights(pi,num_items,item_sizes,problem_instance) for j in range(N)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Average Approximation model \n",
    "\\begin{align*}\n",
    "    \\max_{x, \\varepsilon_u,\\eta, S_u } \\; (1-\\beta) \\left [ \\frac{1}{N} \\sum_{u=1}^N \\left ( \\sum_{i=1}^{10} r_i W^{u}_i x_i - p \\varepsilon_u \\right ) \\right ] + \\beta \\left [ \\eta - \\frac{1}{1-\\alpha} \\frac{1}{N} \\sum_{u=1 }^N S_u \\right ] \\tag{SAA}\n",
    "    \\end{align*}\n",
    "subject to \n",
    "    \\begin{align*}\n",
    "    \\begin{aligned}\n",
    "     x_i & \\in \\{0,1\\} & \\quad & \\text{ for all } i \\in I \\\\\n",
    "     \\varepsilon_u & \\geq 0 & \\quad & \\text{ for all } u \\in U \\\\\n",
    "    \\varepsilon_u & \\geq \\sum_{i=1} ^{10} W^{u}_i x_i - K  & \\quad &  \\text{ for all } u \\in U \\\\\n",
    "    S_u & \\geq 0 & \\quad & \\text{ for all } u \\in U \\\\\n",
    "    S_u & \\geq \\eta - \\left ( \\sum_{i=1}^{10} r_i W^{u}_i x_i - p \\varepsilon_u \\right ) & \\quad & \\text{ for all } u \\in U.\n",
    "    \\end{aligned}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model implentation in Gurobi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gurobi_optimization_SAA(problem_instance,beta,alpha,r,p,K,N):\n",
    "\n",
    "    # Generate scenarios for problem instance\n",
    "    scenario_weights = generateScenarios_SAA(pi,num_items,item_sizes,problem_instance,N)\n",
    "    scenarios = range(len(scenario_weights))\n",
    "    scenario_probabilities = [1/N for j in range(N)]\n",
    "    \n",
    "    # Misc\n",
    "    items = range(num_items)\n",
    "    \n",
    "\n",
    "    if beta == 0:\n",
    "        alpha = alpha[\"EV\"]\n",
    "    else:\n",
    "        alpha = alpha[\"CVaR\"]\n",
    "    \n",
    "    # Create empty model\n",
    "    m = gb.Model()\n",
    "    m.setParam('OutputFlag', 0)\n",
    "\n",
    "    # Create variables \n",
    "    x = m.addVars(items, vtype=gb.GRB.BINARY, name= \"x\")\n",
    "    eta = m.addVars(1, vtype=gb.GRB.CONTINUOUS, name=\"eta\")\n",
    "    epsilon = m.addVars(scenarios, vtype=gb.GRB.CONTINUOUS, name=\"epsilon\", lb=0) \n",
    "    s = m.addVars(scenarios, vtype=gb.GRB.CONTINUOUS, name=\"s\", lb=0)\n",
    "\n",
    "    # Set objective function\n",
    "    def scenario_profit(scenario):\n",
    "        return gb.quicksum(r[item]*scenario_weights[scenario][item]*x[item]-p*epsilon[scenario] for item in items)\n",
    "\n",
    "    obj_1 = (1-beta)*gb.quicksum(scenario_probabilities[scenario]*scenario_profit(scenario) for scenario in scenarios)\n",
    "    obj_2 = beta*(eta[0]-(1/(1-alpha))*gb.quicksum(scenario_probabilities[scenario]*s[scenario] for scenario in scenarios))\n",
    "\n",
    "    m.setObjective(obj_1 + obj_2, gb.GRB.MAXIMIZE)\n",
    "\n",
    "    # # Create constraints\n",
    "    # Epsilon constraint\n",
    "    for scenario in scenarios:\n",
    "        m.addConstr(epsilon[scenario] >= gb.quicksum(scenario_weights[scenario][item]*x[item] for item in items) - K)\n",
    "\n",
    "    # S constraint\n",
    "    for scenario in scenarios:\n",
    "        m.addConstr(s[scenario] >= eta[0] - scenario_profit(scenario))\n",
    "\n",
    "    # Solve model\n",
    "    m.optimize()\n",
    "    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve the SAA model $M$ times given a sample of size $N$ to obtain SAA solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution for instance  1\n",
      "SAA solution EV model\n",
      "x =  [0, 0, 0, 1, 0, 0, 0, 1, 1, 1]\n",
      "SAA objective value EV model:  14798.616937481826\n",
      "\n",
      "SAA solution CVaR model\n",
      "x =  [0, 0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
      "eta =  [11661]\n",
      "SAA objective value CVaR model:  10182.533661908854\n"
     ]
    }
   ],
   "source": [
    "N = 2000\n",
    "M = 10\n",
    "problem_instance = 0 \n",
    "SAA_solve_EV = [gurobi_optimization_SAA(problem_instance,beta_model[\"EV\"], alpha_model,r,p,K,N) for j in range(M)]\n",
    "SAA_solve_CVaR = [gurobi_optimization_SAA(problem_instance,beta_model[\"CVaR\"], alpha_model,r,p,K,N) for j in range(M)]\n",
    "\n",
    "# Store objective values to compute upper bound on v*\n",
    "SAA_objectiveValues_EV = []\n",
    "SAA_objectiveValues_CVaR = []\n",
    "\n",
    "\n",
    "# Obtain SAA solution, which is the solution corresponding to the maximum out of M optimal values\n",
    "maximumObjective_EV = 0\n",
    "for j in range(M):\n",
    "    SAA_objectiveValues_EV.append(SAA_solve_EV[j].objVal)\n",
    "    \n",
    "    if(SAA_solve_EV[j].objVal > maximumObjective_EV):\n",
    "        maximumObjective_EV = SAA_solve_EV[j].objVal\n",
    "        v_EV = SAA_solve_EV[j].getVars()\n",
    "        SAA_solution_EV = [int(v_EV[i].x) for i in range(len(v_EV)) if (re.sub(\"\\[\\d+\\]\", \"\", v_EV[i].varName) == \"x\")]\n",
    "\n",
    "maximumObjective_CVaR = 0\n",
    "for j in range(M):\n",
    "    SAA_objectiveValues_CVaR.append(SAA_solve_CVaR[j].objVal)\n",
    "    \n",
    "    if(SAA_solve_CVaR[j].objVal > maximumObjective_CVaR):\n",
    "        maximumObjective_CVaR = SAA_solve_CVaR[j].objVal\n",
    "        v_CVaR = SAA_solve_CVaR[j].getVars()\n",
    "        SAA_solution_CVaR = [int(v_CVaR[i].x) for i in range(len(v_CVaR)) if (re.sub(\"\\[\\d+\\]\", \"\", v_CVaR[i].varName) == \"x\")]\n",
    "        SAA_solution_CVaR_eta = [int(v_CVaR[i].x) for i in range(len(v_CVaR)) if (re.sub(\"\\[\\d+\\]\", \"\", v_CVaR[i].varName) == \"eta\")]\n",
    "        \n",
    "print(\"Solution for instance \", problem_instance+1)\n",
    "print(\"SAA solution EV model\")\n",
    "print(\"x = \", SAA_solution_EV)\n",
    "print(\"SAA objective value EV model: \",maximumObjective_EV)\n",
    "print(\"\")\n",
    "print(\"SAA solution CVaR model\")\n",
    "print(\"x = \", SAA_solution_CVaR)\n",
    "print(\"eta = \", SAA_solution_CVaR_eta)\n",
    "print(\"SAA objective value CVaR model: \",maximumObjective_CVaR)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivation of optimality gap\n",
    "\n",
    "The optimality gap is defined by: \n",
    "\\begin{align*}\n",
    "        \\mathrm{gap}(\\hat{x}) =  v^* - g(\\hat{x}),\n",
    "    \\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upper bound for $v^*$ using $E(\\hat{v}_N)$\n",
    "\n",
    "Sample mean of $E(\\hat{v}_N)$:\n",
    "\\begin{align*}\n",
    "        \\bar{v}_{N,M} = \\frac{1}{M} \\sum_{j = 1}^M \\hat{v}^j_N.\n",
    "    \\end{align*}\n",
    "    \n",
    "Sample variance: \n",
    "\n",
    "\\begin{align*}\n",
    "        \\hat{\\sigma}^2_{N,M} = \\frac{1}{M(M-1)} \\sum_{j =1}^M (\\hat{v}^j_N - \\bar{v}_{N,M})^2.\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EV Model: \n",
      "Sample mean:  14606.545704185333\n",
      "Standard deviation of sample mean:  25.10547407513086\n",
      "CVaR Model: \n",
      "Sample mean:  9707.610161999171\n",
      "Standard deviation of sample mean:  84.19643309935367\n"
     ]
    }
   ],
   "source": [
    "# Sample mean\n",
    "sample_mean_UB_EV = np.mean(SAA_objectiveValues_EV)\n",
    "sample_mean_UB_CVaR = np.mean(SAA_objectiveValues_CVaR)\n",
    "\n",
    "# Sample standard deviation\n",
    "sample_std_UB_EV = np.power((np.std(SAA_objectiveValues_EV)**2)/(M-1),0.5)\n",
    "sample_std_UB_CVaR = np.power((np.std(SAA_objectiveValues_CVaR)**2)/(M-1),0.5)\n",
    "\n",
    "print(\"EV Model: \")\n",
    "print(\"Sample mean: \",sample_mean_UB_EV)\n",
    "print(\"Standard deviation of sample mean: \",sample_std_UB_EV)\n",
    "\n",
    "print(\"CVaR Model: \")\n",
    "print(\"Sample mean: \",sample_mean_UB_CVaR)\n",
    "print(\"Standard deviation of sample mean: \",sample_std_UB_CVaR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 95% upper bound for $v^*$\n",
    " \\begin{align*}\n",
    "        U_{N,M} = \\bar{v}_{N,M} + t_{\\gamma,\\nu}\\hat{\\sigma}_{N,M},\n",
    "    \\end{align*}\n",
    "    where $\\nu = M-1$ and $t_{\\gamma,\\nu}$ is the $\\gamma$-critical value of the $t$-distribution with $\\nu$ degrees of freedom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.0 % upper bound (EV model):  14652.566873392856\n",
      "95.0 % upper bound (CVaR model):  9861.951732396903\n"
     ]
    }
   ],
   "source": [
    "nu = M-1\n",
    "gamma = 0.05\n",
    "critical_value_t = stats.t.ppf(1-gamma,nu)\n",
    "\n",
    "gap_UB_EV = sample_mean_UB_EV + critical_value_t*sample_std_UB_EV\n",
    "gap_UB_CVaR = sample_mean_UB_CVaR + critical_value_t*sample_std_UB_CVaR\n",
    "\n",
    "print(100*(1-gamma),\"% upper bound (EV model): \",gap_UB_EV )\n",
    "print(100*(1-gamma),\"% upper bound (CVaR model): \",gap_UB_CVaR )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lower bound for $g(\\hat{x})$ \n",
    "\n",
    "### First generate random sample $W^1, W^2, \\dots, W^{N'}$ of size $N'$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_prime = 10000\n",
    "scenario_weights_SAA = generateScenarios_SAA(pi,num_items,item_sizes,problem_instance,N_prime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Then, compute the sample mean $\\hat{g}_{N'}(\\hat{x})$ and sample variance of $\\hat{g}_{N'}(\\hat{x})$\n",
    "\n",
    "Let \n",
    "    \\begin{align*}\n",
    "        Q(\\hat{x},W^{u}) = (1-\\beta)\\left ( \\sum_{i=1}^{10} r_i W^{u}_i \\hat{x}_i - p \\varepsilon_u \\right ) + \\beta \\left [ \\eta - \\frac{1}{1-\\alpha} S_u \\right ],\n",
    "    \\end{align*}\n",
    "    where $\\varepsilon_u = \\max \\{0, \\sum_{i=1} ^{10} W^{u}_i \\hat{x}_i - K \\}$ and $S_u = \\max \\{0,\\eta - (\\sum_{i=1}^{10} r_i W^{u}_i \\hat{x}_i - p \\varepsilon_u ) \\}$ for all $u \\in U$. \n",
    "    Then, the sample average is given by\n",
    "    \\begin{align*}\n",
    "        \\hat{g}_{N'}(\\hat{x}) = \\frac{1}{N'} \\sum_{u=1 }^{N'}  Q(\\hat{x},W^{u}),\n",
    "    \\end{align*}\n",
    "    and the sample variance of $\\hat{g}_{N'}(\\hat{x})$ is given by\n",
    "    \\begin{align*}\n",
    "        \\hat{\\sigma}^2_{N'}(\\hat{x}) = \\frac{1}{N'(N'-1)} \\sum_{u=1}^{N'} \\left [ Q(\\hat{x},W^{u}) - \\hat{g}_{N'}(\\hat{x}) \\right ]^2.\n",
    "    \\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EV Model: \n",
      "Sample mean:  14634.578610713881\n",
      "Standard deviation of sample mean:  26.15590307524507\n",
      "CVaR Model: \n",
      "Sample mean:  9829.763521671548\n",
      "Standard deviation of sample mean:  114.14266125289681\n"
     ]
    }
   ],
   "source": [
    "def scenario_profit_given_x_hat(x,alpha,beta,r,p,K,eta,scenario_weight):\n",
    "    scenario_excess = max(0,sum(scenario_weight*x)-K)\n",
    "    profit_EV = sum(r*scenario_weight*x)-p*scenario_excess   \n",
    "    profit_CVaR = eta[0]-(1/(1-alpha))*max(0,eta[0]-profit_EV)\n",
    "    return (1-beta)*profit_EV + beta*profit_CVaR\n",
    "\n",
    "LB_scenarios = range(len(scenario_weights_SAA))\n",
    "\n",
    "Q_EV = [scenario_profit_given_x_hat(SAA_solution_EV,0,beta_model[\"EV\"],r,p,K,SAA_solution_CVaR_eta,scenario_weights_SAA[scenario]) for scenario in LB_scenarios]\n",
    "\n",
    "Q_CVaR = [scenario_profit_given_x_hat(SAA_solution_CVaR,0.95,beta_model[\"CVaR\"],r,p,K,SAA_solution_CVaR_eta,scenario_weights_SAA[scenario]) for scenario in LB_scenarios]\n",
    "\n",
    "# Sample mean\n",
    "sample_mean_LB_EV = np.mean(Q_EV)\n",
    "sample_mean_LB_CVaR = np.mean(Q_CVaR)\n",
    "\n",
    "# Sample standard deviation\n",
    "sample_std_LB_EV = np.power((np.std(Q_EV)**2)/(N_prime-1),0.5)\n",
    "sample_std_LB_CVaR = np.power((np.std(Q_CVaR)**2)/(N_prime-1),0.5)\n",
    "\n",
    "print(\"EV Model: \")\n",
    "print(\"Sample mean: \",sample_mean_LB_EV)\n",
    "print(\"Standard deviation of sample mean: \",sample_std_LB_EV)\n",
    "\n",
    "print(\"CVaR Model: \")\n",
    "print(\"Sample mean: \",sample_mean_LB_CVaR)\n",
    "print(\"Standard deviation of sample mean: \",sample_std_LB_CVaR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 95% lower bound for $g(\\hat{x})$\n",
    "\\begin{align*}\n",
    "        L_{N'} = \\hat{g}_{N'}(\\hat{x}) - z_{\\gamma} \\hat{\\sigma}_{N'}(\\hat{x}),\n",
    "    \\end{align*}\n",
    "    where $z_{\\gamma}$ is the $\\gamma$-critical value of the standard normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.0 % lower bound (EV model):  14591.555978674372\n",
      "95.0 % lower bound (CVaR model):  9642.015551319828\n"
     ]
    }
   ],
   "source": [
    "critical_value_z = stats.norm.ppf(1-gamma,0,1)\n",
    "gap_LB_EV = sample_mean_LB_EV - critical_value_z*sample_std_LB_EV\n",
    "gap_LB_CVaR = sample_mean_LB_CVaR - critical_value_z*sample_std_LB_CVaR\n",
    "\n",
    "print(100*(1-gamma),\"% lower bound (EV model): \",gap_LB_EV )\n",
    "print(100*(1-gamma),\"% lower bound (CVaR model): \",gap_LB_CVaR )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 90% confidence bound on the true $\\mathrm{gap}(\\hat{x})$ \n",
    "Gap: \n",
    "    \\begin{align*}\n",
    "        \\widehat{gap}(\\hat{x}) = U_{N,M} - L_{N'}.\n",
    "    \\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.0 % confidence bound on true gap (EV model):  61.01089471848354\n",
      "90.0 % confidence bound on true gap  (CVaR model):  219.93618107707516\n"
     ]
    }
   ],
   "source": [
    "gap_EV = gap_UB_EV - gap_LB_EV\n",
    "gap_CVaR = gap_UB_CVaR - gap_LB_CVaR\n",
    "\n",
    "print(100*(1-2*gamma),\"% confidence bound on true gap (EV model): \",gap_EV )\n",
    "print(100*(1-2*gamma),\"% confidence bound on true gap  (CVaR model): \", gap_CVaR )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate two random sample batches of the weights $W^1,\\dots,W^N$ using $V$ and $1-V$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateWeights_AV(pi,num_items,item_sizes,problem_instance):\n",
    "    V1 = np.random.uniform(size=num_items)\n",
    "    W1 = [item_sizes[problem_instance][\"dh\"][i] if V1[i] < pi[i] else item_sizes[problem_instance][\"dl\"][i] \n",
    "        for i in range(num_items)]\n",
    "    W1 = np.asarray(W1)\n",
    "\n",
    "    V2 = 1-V1\n",
    "    W2 = [item_sizes[problem_instance][\"dh\"][i] if V2[i] < pi[i] else item_sizes[problem_instance][\"dl\"][i] \n",
    "        for i in range(num_items)]\n",
    "    W2 = np.asarray(W2)\n",
    "    \n",
    "    return W1, W2\n",
    "\n",
    "def generateScenarios_SAA_AV(pi,num_items,item_sizes,problem_instance,N): \n",
    "    \n",
    "    scenarios_SAA_AV_1 = []\n",
    "    scenarios_SAA_AV_2 = []\n",
    "    \n",
    "    for j in range(N):\n",
    "        W = generateWeights_AV(pi,num_items,item_sizes,problem_instance)\n",
    "        scenarios_SAA_AV_1.append(W[0])\n",
    "        scenarios_SAA_AV_2.append(W[1])\n",
    "  \n",
    "    return scenarios_SAA_AV_1, scenarios_SAA_AV_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slight edit to Gurobi implementation, i.e. scenario weights are input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gurobi_optimization_SAA_AV(problem_instance,beta,alpha,r,p,K,N,scenario_weights_AV):\n",
    "\n",
    "    # Generate scenarios for problem instance\n",
    "    scenario_weights = scenario_weights_AV\n",
    "    scenarios = range(len(scenario_weights))\n",
    "    scenario_probabilities = [1/N for j in range(N)]\n",
    "    \n",
    "    # Misc\n",
    "    items = range(num_items)\n",
    "    \n",
    "\n",
    "    if beta == 0:\n",
    "        alpha = alpha[\"EV\"]\n",
    "    else:\n",
    "        alpha = alpha[\"CVaR\"]\n",
    "    \n",
    "    # Create empty model\n",
    "    m = gb.Model()\n",
    "    m.setParam('OutputFlag', 0)\n",
    "\n",
    "    # Create variables \n",
    "    x = m.addVars(items, vtype=gb.GRB.BINARY, name= \"x\")\n",
    "    eta = m.addVars(1, vtype=gb.GRB.CONTINUOUS, name=\"eta\")\n",
    "    epsilon = m.addVars(scenarios, vtype=gb.GRB.CONTINUOUS, name=\"epsilon\", lb=0) \n",
    "    s = m.addVars(scenarios, vtype=gb.GRB.CONTINUOUS, name=\"s\", lb=0)\n",
    "\n",
    "    # Set objective function\n",
    "    def scenario_profit(scenario):\n",
    "        return gb.quicksum(r[item]*scenario_weights[scenario][item]*x[item]-p*epsilon[scenario] for item in items)\n",
    "\n",
    "    obj_1 = (1-beta)*gb.quicksum(scenario_probabilities[scenario]*scenario_profit(scenario) for scenario in scenarios)\n",
    "    obj_2 = beta*(eta[0]-(1/(1-alpha))*gb.quicksum(scenario_probabilities[scenario]*s[scenario] for scenario in scenarios))\n",
    "\n",
    "    m.setObjective(obj_1 + obj_2, gb.GRB.MAXIMIZE)\n",
    "\n",
    "    # # Create constraints\n",
    "    # Epsilon constraint\n",
    "    for scenario in scenarios:\n",
    "        m.addConstr(epsilon[scenario] >= gb.quicksum(scenario_weights[scenario][item]*x[item] for item in items) - K)\n",
    "\n",
    "    # S constraint\n",
    "    for scenario in scenarios:\n",
    "        m.addConstr(s[scenario] >= eta[0] - scenario_profit(scenario))\n",
    "\n",
    "    # Solve model\n",
    "    m.optimize()\n",
    "    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve SAA scheme $M$ times \n",
    "Get pairs $(\\hat{v}^{1,1}_N,\\hat{v}^{1,2}_N), (\\hat{v}^{2,1}_N,\\hat{v}^{2,2}_N), \\dots, (\\hat{v}^{M,1}_N,\\hat{v}^{M,2}_N) $\n",
    "\n",
    "Then determine $\\hat{v}^{j}_N = (\\hat{v}^{j,1}_N+\\hat{v}^{j,2}_N)/2$ for all $j=1,\\dots,M$ and get SAA solution $\\hat{x}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 5\n",
    "\n",
    "# Solve EV model\n",
    "SAA_solve_EV_AV = []\n",
    "SAA_EV_maxObjective = 0\n",
    "\n",
    "for j in range(M):\n",
    "    scenario_weights_AV = generateScenarios_SAA_AV(pi,num_items,item_sizes,problem_instance,N)\n",
    "    \n",
    "    # Pairs of solutions \n",
    "    sol1 = gurobi_optimization_SAA_AV(problem_instance,beta_model[\"EV\"], alpha_model,r,p,K,N,scenario_weights_AV[0])\n",
    "    if(sol1.objVal > SAA_EV_maxObjective):\n",
    "        SAA_EV_maxObjective = sol1.objVal\n",
    "        EV_AV = sol1.getVars()\n",
    "        SAA_solution_EV_AV = [int(EV_AV[i].x) for i in range(len(EV_AV)) if (re.sub(\"\\[\\d+\\]\", \"\", EV_AV[i].varName) == \"x\")]\n",
    "        \n",
    "    sol2 = gurobi_optimization_SAA_AV(problem_instance,beta_model[\"EV\"], alpha_model,r,p,K,N,scenario_weights_AV[1])\n",
    "    if(sol2.objVal > SAA_EV_maxObjective):\n",
    "        SAA_EV_maxObjective = sol2.objVal\n",
    "        EV_AV = sol2.getVars()\n",
    "        SAA_solution_EV_AV = [int(EV_AV[i].x) for i in range(len(EV_AV)) if (re.sub(\"\\[\\d+\\]\", \"\", EV_AV[i].varName) == \"x\")]     \n",
    "        \n",
    "    SAA_solve_EV_AV.append((sol1.objVal+sol2.objVal)/2)\n",
    "    \n",
    "# Solve CVaR model\n",
    "SAA_solve_CVaR_AV = []\n",
    "SAA_CVaR_maxObjective = 0\n",
    "\n",
    "for j in range(M):\n",
    "    scenario_weights_AV = generateScenarios_SAA_AV(pi,num_items,item_sizes,problem_instance,N)\n",
    "    \n",
    "    # Pairs of solutions \n",
    "    sol1 = gurobi_optimization_SAA_AV(problem_instance,beta_model[\"CVaR\"], alpha_model,r,p,K,N,scenario_weights_AV[0])\n",
    "    if(sol1.objVal > SAA_CVaR_maxObjective):\n",
    "        SAA_CVaR_maxObjective = sol1.objVal\n",
    "        CVaR_AV = sol1.getVars()\n",
    "        SAA_solution_CVaR_AV = [int(CVaR_AV[i].x) for i in range(len(CVaR_AV)) if (re.sub(\"\\[\\d+\\]\", \"\", CVaR_AV[i].varName) == \"x\")]\n",
    "        SAA_solution_CVaR_eta_AV = [int(CVaR_AV[i].x) for i in range(len(CVaR_AV)) if (re.sub(\"\\[\\d+\\]\", \"\", CVaR_AV[i].varName) == \"eta\")]\n",
    "        \n",
    "    sol2 = gurobi_optimization_SAA_AV(problem_instance,beta_model[\"CVaR\"], alpha_model,r,p,K,N,scenario_weights_AV[1])\n",
    "    if(sol2.objVal > SAA_CVaR_maxObjective):\n",
    "        SAA_CVaR_maxObjective = sol2.objVal\n",
    "        CVaR_AV = sol2.getVars()\n",
    "        SAA_solution_CVaR_AV = [int(CVaR_AV[i].x) for i in range(len(CVaR_AV)) if (re.sub(\"\\[\\d+\\]\", \"\", CVaR_AV[i].varName) == \"x\")]     \n",
    "        SAA_solution_CVaR_eta_AV = [int(CVaR_AV[i].x) for i in range(len(CVaR_AV)) if (re.sub(\"\\[\\d+\\]\", \"\", CVaR_AV[i].varName) == \"eta\")]\n",
    "        \n",
    "    SAA_solve_CVaR_AV.append((sol1.objVal+sol2.objVal)/2)\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EV model: \n",
      "SAA solution with antithetic variates:  [0, 0, 0, 1, 0, 0, 0, 1, 1, 1]\n",
      "Objective value of SAA solution:  14799.020897927941\n",
      "\n",
      "Sample mean with AV:  14613.971620961005\n",
      "Standard deviation of sample mean with AV:  17.708994246410935\n",
      "\n",
      "Sample mean without AV:  14606.545704185333\n",
      "Standard deviation of sample mean without AV:  25.10547407513086\n",
      "\n",
      "CVaR model: \n",
      "SAA solution with antithetic variates: x=  [0, 0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
      "SAA solution with antithetic variates: eta=  [11661]\n",
      "Objective value of SAA solution:  9826.402603952292\n",
      "\n",
      "Sample mean with AV:  9632.954170422705\n",
      "Standard deviation of sample mean with AV:  53.01568345216329\n",
      "\n",
      "Sample mean without AV:  9707.610161999171\n",
      "Standard deviation of sample mean without AV:  84.19643309935367\n"
     ]
    }
   ],
   "source": [
    "# SAA solution EV model\n",
    "print(\"EV model: \")\n",
    "print(\"SAA solution with antithetic variates: \", SAA_solution_EV_AV)\n",
    "print(\"Objective value of SAA solution: \", SAA_EV_maxObjective)\n",
    "print(\"\")\n",
    "\n",
    "# Sample mean\n",
    "sample_mean_UB_EV_AV = np.mean(SAA_solve_EV_AV)\n",
    "\n",
    "\n",
    "# Sample standard deviation\n",
    "sample_std_UB_EV_AV = np.power((np.std(SAA_solve_EV_AV)**2)/(M-1),0.5)\n",
    "\n",
    "\n",
    "print(\"Sample mean with AV: \",sample_mean_UB_EV_AV)\n",
    "print(\"Standard deviation of sample mean with AV: \",sample_std_UB_EV_AV)\n",
    "print(\"\")\n",
    "print(\"Sample mean without AV: \",sample_mean_UB_EV)\n",
    "print(\"Standard deviation of sample mean without AV: \",sample_std_UB_EV)\n",
    "print(\"\")\n",
    "\n",
    "# SAA solution CVaR model\n",
    "print(\"CVaR model: \")\n",
    "print(\"SAA solution with antithetic variates: x= \", SAA_solution_CVaR_AV)\n",
    "print(\"SAA solution with antithetic variates: eta= \", SAA_solution_CVaR_eta_AV)\n",
    "print(\"Objective value of SAA solution: \", SAA_CVaR_maxObjective)\n",
    "print(\"\")\n",
    "\n",
    "# Sample mean\n",
    "sample_mean_UB_CVaR_AV = np.mean(SAA_solve_CVaR_AV)\n",
    "\n",
    "\n",
    "# Sample standard deviation\n",
    "sample_std_UB_CVaR_AV = np.power((np.std(SAA_solve_CVaR_AV)**2)/(M-1),0.5)\n",
    "\n",
    "\n",
    "print(\"Sample mean with AV: \",sample_mean_UB_CVaR_AV)\n",
    "print(\"Standard deviation of sample mean with AV: \",sample_std_UB_CVaR_AV)\n",
    "print(\"\")\n",
    "print(\"Sample mean without AV: \",sample_mean_UB_CVaR)\n",
    "print(\"Standard deviation of sample mean without AV: \",sample_std_UB_CVaR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate two random sample batches of the weights $W^1,\\dots,W^{N'}$ using $V$ and $1-V$ and obtain $Q_1(\\hat{x},W^1), \\dots, Q_1(\\hat{x},W^{N'})$ and $Q_2(\\hat{x},W^1), \\dots, Q_2(\\hat{x},W^{N'})$\n",
    "\n",
    "Then compute $Q(\\hat{x},W^u) =  (Q_1(\\hat{x},W^u)+Q_2(\\hat{x},W^u))/2 $ for all $u =1,\\dots, N'$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EV Model: \n",
      "Sample mean with AV:  14630.609867165347\n",
      "Standard deviation of sample mean with AV:  21.590311670248905\n",
      "\n",
      "Sample mean without AV:  14634.578610713881\n",
      "Standard deviation of sample mean without AV:  26.15590307524507\n",
      "CVaR Model: \n",
      "Sample mean with AV:  9590.864007610167\n",
      "Standard deviation of sample mean with AV:  122.15160843418145\n",
      "\n",
      "Sample mean without AV:  9829.763521671548\n",
      "Standard deviation of sample mean without AV:  114.14266125289681\n"
     ]
    }
   ],
   "source": [
    "N_prime = 5000\n",
    "scenario_weights_SAA_AV = generateScenarios_SAA_AV(pi,num_items,item_sizes,problem_instance,N_prime)\n",
    "\n",
    "LB_scenarios_AV = range(len(scenario_weights_SAA_AV[0]))\n",
    "\n",
    "Q_EV_AV_1 = [scenario_profit_given_x_hat(SAA_solution_EV_AV,0,beta_model[\"EV\"],r,p,K,SAA_solution_CVaR_eta_AV,scenario_weights_SAA_AV[0][scenario]) for scenario in LB_scenarios_AV]\n",
    "Q_EV_AV_2 = [scenario_profit_given_x_hat(SAA_solution_EV_AV,0,beta_model[\"EV\"],r,p,K,SAA_solution_CVaR_eta_AV,scenario_weights_SAA_AV[1][scenario]) for scenario in LB_scenarios_AV]\n",
    "\n",
    "Q_CVaR_AV_1 = [scenario_profit_given_x_hat(SAA_solution_CVaR_AV,0.95,beta_model[\"CVaR\"],r,p,K,SAA_solution_CVaR_eta_AV,scenario_weights_SAA_AV[0][scenario]) for scenario in LB_scenarios_AV]\n",
    "Q_CVaR_AV_2 = [scenario_profit_given_x_hat(SAA_solution_CVaR_AV,0.95,beta_model[\"CVaR\"],r,p,K,SAA_solution_CVaR_eta_AV,scenario_weights_SAA_AV[1][scenario]) for scenario in LB_scenarios_AV]\n",
    "\n",
    "Q_EV_AV = (np.array(Q_EV_AV_1)+np.array(Q_EV_AV_2))/2\n",
    "Q_CVaR_AV = (np.array(Q_CVaR_AV_1)+np.array(Q_CVaR_AV_2))/2\n",
    "\n",
    "\n",
    "# Sample mean\n",
    "sample_mean_LB_EV_AV = np.mean(Q_EV_AV)\n",
    "sample_mean_LB_CVaR_AV = np.mean(Q_CVaR_AV)\n",
    "\n",
    "# Sample standard deviation\n",
    "sample_std_LB_EV_AV = np.power((np.std(Q_EV_AV)**2)/(N_prime-1),0.5)\n",
    "sample_std_LB_CVaR_AV = np.power((np.std(Q_CVaR_AV)**2)/(N_prime-1),0.5)\n",
    "\n",
    "print(\"EV Model: \")\n",
    "print(\"Sample mean with AV: \",sample_mean_LB_EV_AV)\n",
    "print(\"Standard deviation of sample mean with AV: \",sample_std_LB_EV_AV)\n",
    "print(\"\")\n",
    "print(\"Sample mean without AV: \",sample_mean_LB_EV)\n",
    "print(\"Standard deviation of sample mean without AV: \",sample_std_LB_EV)\n",
    "\n",
    "\n",
    "print(\"CVaR Model: \")\n",
    "print(\"Sample mean with AV: \",sample_mean_LB_CVaR_AV)\n",
    "print(\"Standard deviation of sample mean with AV: \",sample_std_LB_CVaR_AV)\n",
    "print(\"\")\n",
    "print(\"Sample mean without AV: \",sample_mean_LB_CVaR)\n",
    "print(\"Standard deviation of sample mean without AV: \",sample_std_LB_CVaR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine $90\\%$ confidence bound on the true $\\mathrm{gap}(\\hat{x})$ using antithetic variates \n",
    "\n",
    "Gap is given by\n",
    "    \\begin{align*}\n",
    "        \\widehat{gap}(\\hat{x}) = U_{N,M} - L_{N'}.\n",
    "    \\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.0 % confidence bound on true gap (EV model) with AV:  81.07210215475789\n",
      "90.0 % confidence bound on true gap  (CVaR model) with AV:  640.1483225386692\n",
      "\n",
      "90.0 % confidence bound on true gap (EV model) without AV:  36.76286103219172\n",
      "90.0 % confidence bound on true gap  (CVaR model) without AV:  878.5361801632025\n"
     ]
    }
   ],
   "source": [
    "# Upper bound\n",
    "nu = M-1\n",
    "gamma = 0.05\n",
    "critical_value_t_AV = stats.t.ppf(1-gamma,nu)\n",
    "\n",
    "gap_UB_EV_AV = sample_mean_UB_EV_AV + critical_value_t_AV*sample_std_UB_EV_AV\n",
    "gap_UB_CVaR_AV = sample_mean_UB_CVaR_AV + critical_value_t*sample_std_UB_CVaR_AV\n",
    "\n",
    "# Lower bound\n",
    "critical_value_z_AV = stats.norm.ppf(1-gamma,0,1)\n",
    "gap_LB_EV_AV = sample_mean_LB_EV_AV - critical_value_z_AV*sample_std_LB_EV_AV\n",
    "gap_LB_CVaR_AV = sample_mean_LB_CVaR_AV - critical_value_z*sample_std_LB_CVaR_AV\n",
    "\n",
    "\n",
    "# Gap \n",
    "gap_EV_AV = gap_UB_EV_AV - gap_LB_EV_AV\n",
    "gap_CVaR_AV = gap_UB_CVaR_AV - gap_LB_CVaR_AV\n",
    "\n",
    "print(100*(1-2*gamma),\"% confidence bound on true gap (EV model) with AV: \",gap_EV_AV )\n",
    "print(100*(1-2*gamma),\"% confidence bound on true gap  (CVaR model) with AV: \", gap_CVaR_AV )\n",
    "print(\"\")\n",
    "print(100*(1-2*gamma),\"% confidence bound on true gap (EV model) without AV: \",gap_EV )\n",
    "print(100*(1-2*gamma),\"% confidence bound on true gap  (CVaR model) without AV: \", gap_CVaR )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gurobi_model(r, K, p,scenario_weights, scenario_probabilities, beta=0, alpha=0.95, save_path=None):\n",
    "    model = gb.Model(\"expected_value\")\n",
    "    \n",
    "    num_items = len(scenario_weights[0])\n",
    "    \n",
    "    items = range(num_items)\n",
    "    scenarios = range(len(scenario_weights))\n",
    "    \n",
    "    if beta == 0:\n",
    "        alpha = alpha[\"EV\"]\n",
    "    else:\n",
    "        alpha = alpha[\"CVaR\"]\n",
    "    \n",
    "    # Define variables\n",
    "    x = model.addVars(items, vtype=gb.GRB.BINARY, name= \"x\")\n",
    "    epsilon = model.addVars(scenarios, vtype=gb.GRB.CONTINUOUS, name=\"epsilon\", lb=0)\n",
    "    eta = model.addVars(1, vtype=gb.GRB.CONTINUOUS, name=\"eta\")\n",
    "    s = model.addVars(scenarios, vtype=gb.GRB.CONTINUOUS, name=\"s\", lb=0)\n",
    "\n",
    "    model.update()\n",
    "\n",
    "    #### Write objective ####\n",
    "    obj = gb.LinExpr()\n",
    "\n",
    "    # Expected value objective\n",
    "    for scenario in scenarios:\n",
    "        for item in items:\n",
    "            obj += (1-beta)*scenario_probabilities[scenario]*r[item]*scenario_weights[scenario][item]*x[item]\n",
    "        obj -= (1-beta)*p*epsilon[scenario]\n",
    "\n",
    "    # CVaR Objective:\n",
    "    # Part 1\n",
    "    obj += beta*eta[0]\n",
    "\n",
    "    # Part 2\n",
    "    for scenario in scenarios:\n",
    "        # TODO: ask why we do 1/(1-a); what does it mean in practice (with relation to quantile)\n",
    "        obj -= beta*(1/(1-alpha))*scenario_probabilities[scenario]*s[scenario]\n",
    "\n",
    "    model.setObjective(obj, gb.GRB.MAXIMIZE)\n",
    "\n",
    "    #### Write constraints ####\n",
    "    # Epsilon constraint\n",
    "    for scenario in scenarios:\n",
    "        model.addConstr(epsilon[scenario] >= sum([scenario_weights[scenario][item]*x[item] for item in items]) - K,\n",
    "                        name=f\"epsilon_constraint_scenario_{scenario}\")\n",
    "\n",
    "    # S constraint\n",
    "    for scenario in scenarios:\n",
    "        model.addConstr(s[scenario] >= eta[0] - (sum([r[item]*scenario_weights[scenario][item]*x[item] for item in items])\n",
    "                                                 - p*epsilon[scenario]),\n",
    "                        name=f\"s_constraint_scenario_{scenario}\")\n",
    "    \n",
    "    # Update and, possibly, save model before optimising\n",
    "    model.update()\n",
    "    \n",
    "    if save_path != None:\n",
    "        model.write(f'{save_path}.lp')\n",
    "        \n",
    "    model.optimize()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Part 5\n",
    "# # Part 6\n",
    "\n",
    "# Sample Average Approximation\n",
    "# # Part 7\n",
    "\n",
    "# Analysis\n",
    "# # Part 8\n",
    "\n",
    "# # Part 9\n",
    "\n",
    "# # Bonus"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
