{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Making Under Uncertainty - Assignment 1\n",
    "\n",
    "Group 2:\n",
    "- Martijn Ketelaars (ANR: 120975)\n",
    "- Robbie Reyerse (ANR: 109997)\n",
    "- Rosalien Timmerhuis (ANR: 520618)\n",
    "- Mike Weltevrede (ANR: 756479)\n",
    "\n",
    "This assignment is about the Stochastic Knapsack Problem (SKP). In the general SKP you are choosing a subset among $N$ items $(i= 1,....,N)$ to allocate to a knapsack of capacity $K$. Each item $i$ has a random size of $w_i$ units. We assume that item sizes are statistically independent. If the collective size of the selected items exceeds the capacity, a penalty of $p$ is assessed per unit excess. We assume that item $i$ has an associated per-unit revenue $r_i$ with $r_i < p$. Different objective functions are possible, i.e. maximizing the profit.\n",
    "\n",
    "The binary decision variable $x_i$ takes a value of $1$ if item $i$ is allocated to the knapsack and a value of $0$ otherwise. All items are considered simultaneously and the values of their sizes are unknown before selection decisions are made. In this assignment, the item size $w_i$ can take only two values, namely $d\\_h_i$ and $d\\_l_i$, with probabilities $P(w_i = d\\_h_i ) = \\pi_i$ and $P(w_i = d\\_l_i ) = 1-\\pi_i$.\n",
    "\n",
    "We start by initialising our problem by importing the necessary Python libraries and setting the parameters that are set in stone, namely the number of instances, the number of items $N$, and the variable $g$ (our group number). We also set the parameters $\\alpha$ and $\\beta$, which are needed in our model to signify the extent of risky behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import itertools\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gurobipy as gb\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "num_instances = 10\n",
    "num_items = 10\n",
    "g = 2 # group number\n",
    "alpha_model = {\"EV\": 0, \"CVaR\": 0.95}\n",
    "beta_model = {\"EV\": 0, \"CVaR\": 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of Problem Instances\n",
    "## Part 1\n",
    "In the first part, we want to generate 10 random instances of the Stochastic Knapsack Problem (SKP). For this, we need to generate values for the low weights $d\\_l_i$ using the Poisson distribution. From Lab 2, we know that the `numpy.random` library is the fastest in doing this. For the high weights $d\\_h_i$, we will use the same library, using the `triangular()` function from `numpy.random`. These weights will be stored in `item_sizes`. We use a random seed equal to the instance number to make sure that we get similar results when reproducing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_instance(num_items, g, seed):\n",
    "    \"\"\"Generate a dictionary of `num_items` possible item sizes\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_items : int\n",
    "        Number of items to generate weights for\n",
    "    g : int\n",
    "        Group number\n",
    "    seed : int\n",
    "        Random seed\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    item_sizes : dict\n",
    "        Dictionary containing the possible item sizes\n",
    "    \"\"\"\n",
    "\n",
    "    # Assert inputs are of correct form\n",
    "    assert isinstance(num_items, int), \"num_items is not an int\"\n",
    "    assert isinstance(g, int), \"g is not an int\"\n",
    "    assert isinstance(seed, int), \"seed is not an int\"\n",
    "\n",
    "    # Generate possible item sizes.\n",
    "    np.random.seed(seed)\n",
    "    lam = [math.ceil((i + 1)/2) for i in range(num_items)]\n",
    "    dl = np.minimum(np.random.poisson(lam), 10)\n",
    "    dh = [np.random.triangular(90 + g - (i+1), 100 + g - (i+1), 110 + g - (i+1))\n",
    "          for i in range(num_items)]\n",
    "\n",
    "    item_sizes = {\"dl\": dl, \"dh\": dh}\n",
    "\n",
    "    return item_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will create the instances of the SKP using the function `skp()` defined below. For this, we need to generate the penalty $p = \\left\\lfloor 60 + \\frac{g}{10} \\right\\rfloor$ and the knapsack capacity $K = 400+4g$, as well as the item size probability vector `pi`, revenue vector `r`, and possible item sizes `item_sizes`. The latter is created using the function `generate_instances()` defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skp(num_instances, num_items, g):\n",
    "    \"\"\"Generates `num_instances` instances of a Stochastic Knapsack Problem (SKP).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_instances : int\n",
    "        Number of instances of the SKP to generate\n",
    "    num_items : int\n",
    "        Number of items to consider per instance\n",
    "    g : int\n",
    "        Group number\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    instance : tuple\n",
    "        Tuple containing the unit excess weight penalty `p`, knapsack capacity `K`, item size\n",
    "        probability vector `pi`, revenue vector `r`, and possible item sizes `item_sizes`,\n",
    "        respectively.\n",
    "    \"\"\"\n",
    "\n",
    "    # Assert inputs are of correct form\n",
    "    assert isinstance(num_instances, int), \"num_instances is not an int\"\n",
    "    assert isinstance(num_items, int), \"num_items is not an int\"\n",
    "    assert isinstance(g, int), \"g is not an int\"\n",
    "\n",
    "    # Generate instance variables\n",
    "    p = math.floor(60 + 0.1 * g)  # Unit excess weight penalty\n",
    "    K = 400 + 4 * g  # Knapsack capacity\n",
    "\n",
    "    pi = np.asarray([0.5 + 0.05 * (i + 1) - 0.001 for i in range(num_items)])\n",
    "    r = np.asarray([51 - (i + 1) for i in range(num_items)])\n",
    "\n",
    "    item_sizes = {j: generate_instance(num_items, g, seed=j) for j in range(num_instances)}\n",
    "\n",
    "    instance = (p, K, pi, r, item_sizes)\n",
    "\n",
    "    return instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penalty: 60\n",
      "Capacity: 408\n",
      "Probabilities: [0.549 0.599 0.649 0.699 0.749 0.799 0.849 0.899 0.949 0.999]\n",
      "Revenues: [50 49 48 47 46 45 44 43 42 41]\n"
     ]
    }
   ],
   "source": [
    "p, K, pi, r, item_sizes = skp(num_instances, num_items, g)\n",
    "\n",
    "print(\"Penalty:\", p)\n",
    "print(\"Capacity:\", K)\n",
    "print(\"Probabilities:\", pi)\n",
    "print(\"Revenues:\", r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heuristic Algorithm\n",
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we develop a simple greedy heuristic algorithm to suggest an item selection strategy for the SKP problem\n",
    "described above. In each iteration we try to add the item (from the set of remaining items) for which its revenue is highest. If we are not able to add this item (because its expected weight exceeds the remaining capacity of the knapsack) and there are still other items that have not been considered, it may as well be possible that one of those items can be added instead.  We continue until either there are no more items to consider or the knapsack is full."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_algorithm(problem_instance, pi, r, item_sizes, K):\n",
    "    \"\"\"Using a greedy algorithm, selects items to use in a Stochastic Knapsack Problem.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    problem_instance : int\n",
    "        Integer specifying which problem instance to take. Note that this number needs to be a key\n",
    "        in `item_sizes`.\n",
    "    pi : list or numpy.array\n",
    "        Probabilities specifying whether an item will attain a high weight.\n",
    "    r : list or numpy.array\n",
    "        Per-unit revenue. Note that this means that if we take M amounts of item i, then the\n",
    "        revenue is r[i]*M, not r[i].\n",
    "    item_sizes : dict\n",
    "        Dictionary with as keys the problem instance number and as values a dictionary of which the\n",
    "        keys are 'dl' and 'dh', specifying the low and high weight, respectively, and the values are\n",
    "        the corresponding weights for each item.\n",
    "    K : int\n",
    "        Knapsack capacity.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    x : numpy.array\n",
    "        Specifies which items are selected with a 1 if an item is selected and 0 otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute expectation of w_i for each item\n",
    "    Ew = item_sizes[problem_instance][\"dh\"] * np.array(pi) + \\\n",
    "        item_sizes[problem_instance][\"dl\"] * (np.array(1) - pi)\n",
    "\n",
    "    sorted_expected_revenue = np.argsort(r)[::-1]\n",
    "\n",
    "    # Initialise zero-value x and W\n",
    "    x = np.zeros(10, dtype=np.int16)\n",
    "    W = 0\n",
    "\n",
    "    while len(sorted_expected_revenue) != 0:\n",
    "\n",
    "        consider_item = sorted_expected_revenue[0]\n",
    "\n",
    "        if W + Ew[consider_item] <= K:\n",
    "            x[consider_item] = 1\n",
    "            W = W + Ew[consider_item]\n",
    "\n",
    "        sorted_expected_revenue = np.delete(sorted_expected_revenue, 0)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Simulation\n",
    "## Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our greedy heuristic algorithm, we will generate decision variables for the first problem instance. Note that we take `problem_instance` equal to 0 since Python is zero-indexed and we started counting at 0 when generating the instances in the beginning of this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [1 1 1 1 1 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "problem_instance = 0\n",
    "x = greedy_algorithm(problem_instance, pi, r, item_sizes, K)\n",
    "print(\"x:\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the possible item sizes and the probability vector `pi`, we can generate the actual weights of the items for a specific problem instance. When a randomly drawn $Uniform(0, 1)$ variable exceeds the relevant probability in `pi`, the weight chosen for that item is $d\\_l_i$. Else, we select weight $d\\_h_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_weights(item_sizes, pi, problem_instance):\n",
    "\n",
    "    num_items = len(pi)\n",
    "\n",
    "    u = np.random.uniform(size=num_items)\n",
    "    w = [item_sizes[problem_instance][\"dh\"][i] if u[i] < pi[i]\n",
    "         else item_sizes[problem_instance][\"dl\"][i] for i in range(num_items)]\n",
    "    w = np.asarray(w)\n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the weight generating function and a decision vector `x`, we can calculate the actual profit for that decision vector. This is simulated in `calculate_profits()` below, taking a certain number of runs `num_runs` to do so. When the realised weight exceeds $K$, we apply athe penalty $p$ for every unit exceeding $K$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_profits(item_sizes, x, r, pi, problem_instance, num_runs):\n",
    "    \"\"\"Calculates the profits based on realised item sizes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    item_sizes : dict\n",
    "        Dictionary with as keys the problem instance number and as values a dictionary of which the\n",
    "        keys are 'dl' and 'dh', specifying the low and high weight, respectively, and the values are\n",
    "        the corresponding weights for each item.\n",
    "    x : numpy.array\n",
    "        Specifies which items are selected with a 1 if an item is selected and 0 otherwise.\n",
    "    r : list or numpy.array\n",
    "        Per-unit revenue. Note that this means that if we take M amounts of item i, then the\n",
    "        revenue is r[i]*M, not r[i].\n",
    "    pi : list or numpy.array\n",
    "        Probabilities specifying whether an item will attain a high weight.\n",
    "    problem_instance : int\n",
    "        Integer specifying which problem instance to take. Note that this number needs to be a key\n",
    "        in `item_sizes`.\n",
    "    num_runs : int\n",
    "        Integer specifying the number of runs for which to calculate the profits.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    profits : numpy.array\n",
    "        Specifies the profits following `num_runs` simulations of instance `problem_instance`.\n",
    "    \"\"\"\n",
    "\n",
    "    profits = []\n",
    "    num_items = len(x)\n",
    "\n",
    "    for run in range(num_runs):\n",
    "        w = generate_weights(item_sizes, pi, problem_instance)\n",
    "\n",
    "        total_weight = np.dot(x, w)\n",
    "        excess = max(total_weight-K, 0)\n",
    "\n",
    "        print(\"Excess =\", total_weight-K)\n",
    "        \n",
    "        profit = np.dot(x, r*w) - excess*p\n",
    "        profits.append(profit)\n",
    "\n",
    "    profits = sorted(profits)\n",
    "\n",
    "    return profits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to calculate the optimal number of runs for running our Monte Carlo simulation. For this, we need to first get an estimate for the standard deviation of the distribution of the profits using a sample run (we use `num_runs` equal to 1000). Note that this standard deviation is defined as \n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\left(\\frac{1}{M(M-1)} \\sum_{j=1}^M \\left(profits_i - \\overline{profits}\\right)\\right)^{\\frac{1}{2}},\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "where $M$ is the number of runs, since we take the standard deviation of the sample mean. Using `ddof=1` in the `numpy.std()` function means that we use $M-1$ to achieve the unbiased estimator, meaning we still need to multiply by $\\sqrt{\\frac{1}{M}}$ to achieve the expression above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excess = -101.64133159696996\n",
      "Excess = -16.177946166797426\n",
      "Excess = 181.07945852308808\n",
      "Excess = -192.15895953092001\n",
      "Excess = -106.58755921499755\n",
      "Excess = 83.55055741048716\n",
      "Excess = -104.38795675031383\n",
      "Excess = -15.761581945991907\n",
      "Excess = -16.177946166797426\n",
      "Excess = -13.014956792648093\n",
      "Excess = 83.55055741048716\n",
      "Excess = -98.47834222282063\n",
      "Excess = -106.69557410074742\n",
      "Excess = 83.55055741048716\n",
      "Excess = 181.07945852308808\n",
      "Excess = -209.1707028313759\n",
      "Excess = -94.63005841831915\n",
      "Excess = 81.35095494580344\n",
      "Excess = -109.44219925409129\n",
      "Excess = -89.26746657948604\n",
      "Mean profit: 15851.300088059254 | Sigma: 607.3118720562264\n"
     ]
    }
   ],
   "source": [
    "# Calculate number of runs; first a test run to get an estimate for sigma\n",
    "num_runs = 20\n",
    "profits = calculate_profits(item_sizes, x, r, pi, problem_instance=problem_instance,\n",
    "                            num_runs=num_runs)\n",
    "sigma = np.std(profits, ddof=1) * math.sqrt(1/num_runs)\n",
    "\n",
    "print(f\"Mean profit: {np.mean(profits)} | Sigma: {sigma}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'd like to show the distribution of the profits. Due to the jumps between selecting a certain number of high and low weights, the distribution looks highly irregular. As such, results may not necessarily be reliable. Nonetheless, as advised by dr. Merzifonluoglu, we still take the approach as discussed in the first few lectures, using the half-width. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAATTklEQVR4nO3df+xldZ3f8eeroCa7aoHlC5nwYwfMaBabdqDfUBqLsUt3BdyK7lYL2ehUaUdbSLTapKjJappswuqytmZbyLgSoEEEF4kki60TYiSbLuh3cMRhERlw1IHpzFewaqKxHXz3j3u+evn6/c73zvecO98Ln+cjubnnfu4597zPuff7+p77Ofeck6pCkvTC93c2ugBJ0rFh4EtSIwx8SWqEgS9JjTDwJakRx290AQAnn3xybd68eaPLkKTnlV27dn2/quYmHX8mAn/z5s0sLCxsdBmS9LyS5DtHM75dOpLUCANfkhph4EtSIwx8SWqEgS9JjTDwJakRBr4kNcLAl6RGGPiS1IiZONJWkmbV5mv+6hfD+659wwZW0p9b+JLUCANfkhph4EtSIwx8SWqEgS9JjTDwJakRBr4kNWLNwE9yRpIvJXkkycNJ3tO1n5RkZ5LHuvsTu/Yk+USSvUkeSnLetBdCkrS2SbbwDwPvr6rfAi4ArkpyDnANcG9VbQHu7R4DXAJs6W7bgesHr1qSdNTWDPyqOlBVD3bDPwYeAU4DLgNu7ka7GXhTN3wZcEuN3A+ckGTT4JVLko7KUfXhJ9kMnAs8AJxaVQdg9E8BOKUb7TTge2OT7e/alr/W9iQLSRYWFxePvnJJ0lGZOPCTvBS4E3hvVf3oSKOu0Fa/0lC1o6rmq2p+bm5u0jIkSes0UeAneRGjsL+1qj7XNR9c6qrp7g917fuBM8YmPx14aphyJUnrNcmvdAJ8Cnikqv5s7Km7gW3d8Dbg82Ptb+9+rXMB8MOlrh9J0saZ5PTIrwHeBnwjye6u7YPAtcAdSa4Evgu8pXvuHuBSYC/wE+Adg1YsSVqXNQO/qv6alfvlAS5aYfwCrupZlyRpYB5pK0mNMPAlqREGviQ1wsCXpEYY+JLUCANfkhph4EtSIwx8SWqEgS9JjTDwJakRBr4kNcLAl6RGGPiS1AgDX5IaYeBLUiMMfElqxCSXOLwxyaEke8babk+yu7vtW7oSVpLNSX469twN0yxekjS5SS5xeBPw58AtSw1V9S+XhpNcB/xwbPzHq2rrUAVKkoYxySUO70uyeaXnugucvxX47WHLkiQNrW8f/oXAwap6bKztrCRfS/LlJBeuNmGS7UkWkiwsLi72LEOStJa+gX8FcNvY4wPAmVV1LvA+4NNJXr7ShFW1o6rmq2p+bm6uZxmSpLWsO/CTHA/8PnD7UltV/ayqnu6GdwGPA6/sW6Qkqb8+W/j/DPhmVe1fakgyl+S4bvhsYAvwRL8SJUlDmORnmbcBfwO8Ksn+JFd2T13Oc7tzAF4LPJTk68BfAu+uqmeGLFiStD6T/ErnilXa/9UKbXcCd/YvS5I0NI+0laRGGPiS1AgDX5IaYeBLUiMMfElqhIEvSY0w8CWpEQa+JDXCwJekRhj4ktQIA1+SGmHgS1IjDHxJaoSBL0mNMPAlqRGTXADlxiSHkuwZa/tIkieT7O5ul44994Eke5M8muT10ypcknR0JtnCvwm4eIX2j1fV1u52D0CScxhdCevV3TT/bemSh5KkjbVm4FfVfcCklym8DPhMdzHzbwN7gfN71CdJGkifPvyrkzzUdfmc2LWdBnxvbJz9XduvSLI9yUKShcXFxR5lSJImsd7Avx54BbAVOABc17VnhXFrpReoqh1VNV9V83Nzc+ssQ5I0qXUFflUdrKpnq+rnwCf5ZbfNfuCMsVFPB57qV6IkaQjrCvwkm8YevhlY+gXP3cDlSV6S5CxgC/CVfiVKkoZw/FojJLkNeB1wcpL9wIeB1yXZyqi7Zh/wLoCqejjJHcDfAoeBq6rq2emULkk6GmsGflVdsULzp44w/h8Df9ynKEnS8DzSVpIaYeBLUiMMfElqhIEvSY0w8CWpEQa+JDXCwJekRhj4ktQIA1+SGmHgS1IjDHxJaoSBL0mNMPAlqREGviQ1wsCXpEYY+JLUiDUDP8mNSQ4l2TPW9rEk30zyUJK7kpzQtW9O8tMku7vbDdMsXpI0uUm28G8CLl7WthP4e1X194FvAR8Ye+7xqtra3d49TJmSpL7WDPyqug94ZlnbF6vqcPfwfuD0KdQmSRrQEH347wS+MPb4rCRfS/LlJBeuNlGS7UkWkiwsLi4OUIYk6Uh6BX6SDwGHgVu7pgPAmVV1LvA+4NNJXr7StFW1o6rmq2p+bm6uTxmSpAmsO/CTbAN+D/jDqiqAqvpZVT3dDe8CHgdeOUShkqR+1hX4SS4G/iPwxqr6yVj7XJLjuuGzgS3AE0MUKknq5/i1RkhyG/A64OQk+4EPM/pVzkuAnUkA7u9+kfNa4D8lOQw8C7y7qp5Z8YUlScfUmoFfVVes0PypVca9E7izb1GSpOF5pK0kNcLAl6RGGPiS1AgDX5IaYeBLUiMMfElqhIEvSY0w8CWpEQa+JDXCwJekRhj4ktQIA1+SGmHgS1IjDHxJaoSBL0mNmCjwk9yY5FCSPWNtJyXZmeSx7v7Erj1JPpFkb5KHkpw3reIlSZObdAv/JuDiZW3XAPdW1Rbg3u4xwCWMLm24BdgOXN+/TElSXxMFflXdByy/VOFlwM3d8M3Am8bab6mR+4ETkmwaolhJ0vqteYnDIzi1qg4AVNWBJKd07acB3xsbb3/XdmB84iTbGX0D4Mwzz+xRhiQde5uv+atfDO+79g0bWMnkprHTNiu01a80VO2oqvmqmp+bm5tCGZKkcX0C/+BSV013f6hr3w+cMTbe6cBTPeYjSRpAn8C/G9jWDW8DPj/W/vbu1zoXAD9c6vqRJG2cifrwk9wGvA44Ocl+4MPAtcAdSa4Evgu8pRv9HuBSYC/wE+AdA9csSVqHiQK/qq5Y5amLVhi3gKv6FCVJGp5H2kpSIwx8SWqEgS9JjTDwJakRBr4kNcLAl6RGGPiS1AgDX5Ia0edsmZL0gjR+JswXEgNfkib0fP9HYJeOJDXCwJekRhj4ktQIA1+SGmHgS1Ij1v0rnSSvAm4fazob+CPgBODfAItd+wer6p51VyhJGsS6A7+qHgW2AiQ5DngSuIvRFa4+XlV/OkiFkqRBDNWlcxHweFV9Z6DXkyQNbKgDry4Hbht7fHWStwMLwPur6gcDzUeS1jR+gNS+a9+wgZXMlt5b+EleDLwR+GzXdD3wCkbdPQeA61aZbnuShSQLi4uLK40iSRrQEF06lwAPVtVBgKo6WFXPVtXPgU8C5680UVXtqKr5qpqfm5sboAxJ0pEMEfhXMNadk2TT2HNvBvYMMA9JUk+9+vCT/BrwO8C7xpo/mmQrUMC+Zc9JkjZIr8Cvqp8Av7Gs7W29KpIkTYVH2kpSIwx8SWqEgS9JjfCKV5I0oFk+6MstfElqhIEvSY0w8CWpEQa+JDXCwJekRhj4ktQIA1+SGmHgS1IjPPBKatgsHySk4Rn4kjQls/YP1S4dSWqEgS9JjejdpZNkH/Bj4FngcFXNJzkJuB3YzOiqV2+tqh/0nZckaf2G2sL/p1W1tarmu8fXAPdW1Rbg3u6xJGkDTatL5zLg5m74ZuBNU5qPJGlCQwR+AV9MsivJ9q7t1Ko6ANDdn7J8oiTbkywkWVhcXBygDEnSkQzxs8zXVNVTSU4Bdib55iQTVdUOYAfA/Px8DVCHJOkIem/hV9VT3f0h4C7gfOBgkk0A3f2hvvORJPXTK/CT/HqSly0NA78L7AHuBrZ1o20DPt9nPpKk/vp26ZwK3JVk6bU+XVX/I8lXgTuSXAl8F3hLz/lIknrqFfhV9QTwD1Zofxq4qM9rS5KG5ZG2ktQIA1+SGmHgS1IjDHxJaoTnw5c0sVk7v7uOjlv4ktQIA1+SGmHgS1IjDHxJaoSBL0mNMPAlqREGviQ1wsCXpEYY+JLUCI+0VXM8WlStWvcWfpIzknwpySNJHk7ynq79I0meTLK7u106XLmSpPXqs4V/GHh/VT3YXeZwV5Kd3XMfr6o/7V+eJGko6w78qjoAHOiGf5zkEeC0oQqTtHHs9nphGmSnbZLNwLnAA13T1UkeSnJjkhNXmWZ7koUkC4uLi0OUIUk6gt6Bn+SlwJ3Ae6vqR8D1wCuArYy+AVy30nRVtaOq5qtqfm5urm8ZkqQ19Ar8JC9iFPa3VtXnAKrqYFU9W1U/Bz4JnN+/TElSX+vuw08S4FPAI1X1Z2Ptm7r+fYA3A3v6lShpFtnP//zT51c6rwHeBnwjye6u7YPAFUm2AgXsA97Vq0JJ0iD6/Ernr4Gs8NQ96y9HkjQtnlpBkhph4EtSIzyXjqRBuTN3dhn4knSMbdQ/Rbt0JKkRBr4kNcIuHekFrm/3wfj0en5zC1+SGmHgS1Ij7NJR01brrlit68OfHOr5zC18SWqEW/iSdAzMws5vA19awyz8oUpDMPAb9ELqh15tWZaH9PN9OWed/xSfHwx8aQUGmF6IDHxJU/NC+jb5QjC1wE9yMfBfgOOAv6iqa6c1L0mzz/DfeFMJ/CTHAf8V+B1gP/DVJHdX1d9OY36t8Q9H0npMawv/fGBvVT0BkOQzwGXAVALfAPylSXdiSmpPqmr4F03+BXBxVf3r7vHbgH9UVVePjbMd2N49fBXwNPD9wYsZ1snMdo2zXh/Mfo3W19+s1zjr9cHkNf5mVc1N+qLT2sJf6eLmz/nPUlU7gB2/mCBZqKr5KdUziFmvcdbrg9mv0fr6m/UaZ70+mF6N0zq1wn7gjLHHpwNPTWlekqQJTCvwvwpsSXJWkhcDlwN3T2lekqQJTKVLp6oOJ7ka+J+MfpZ5Y1U9vMZkO9Z4fhbMeo2zXh/Mfo3W19+s1zjr9cGUapzKTltJ0uzx9MiS1AgDX5IaMROBn+TiJI8m2ZvkmmM43zOSfCnJI0keTvKerv0jSZ5Msru7XTo2zQe6Oh9N8vppL0OSfUm+0dWx0LWdlGRnkse6+xO79iT5RFfDQ0nOG3udbd34jyXZNmB9rxpbT7uT/CjJezdyHSa5McmhJHvG2gZbZ0n+Yfee7O2mXelnyOup8WNJvtnVcVeSE7r2zUl+OrYub1irltWWt2d9g72nGf2g44Guvtsz+nHHEOvw9rH69iXZvYHrcLV82bjPYlVt6I3RTt3HgbOBFwNfB845RvPeBJzXDb8M+BZwDvAR4D+sMP45XX0vAc7q6j5umssA7ANOXtb2UeCabvga4E+64UuBLzA6DuIC4IGu/STgie7+xG74xCm9l/8b+M2NXIfAa4HzgD3TWGfAV4B/3E3zBeCSgWr8XeD4bvhPxmrcPD7estdZsZbVlrdnfYO9p8AdwOXd8A3Avx1iHS57/jrgjzZwHa6WLxv2WZyFLfxfnIahqv4vsHQahqmrqgNV9WA3/GPgEeC0I0xyGfCZqvpZVX0b2Muo/mO9DJcBN3fDNwNvGmu/pUbuB05Isgl4PbCzqp6pqh8AO4GLp1DXRcDjVfWdNWqf6jqsqvuAZ1aYb+911j338qr6mxr9xd0y9lq9aqyqL1bV4e7h/YyOX1nVGrWstrzrru8Ijuo97bZCfxv4y/XWt1aN3TzeCtx2pNeY8jpcLV827LM4C4F/GvC9scf7OXLoTkWSzcC5wANd09Xd16obx77KrVbrNJehgC8m2ZXR6SgATq2qAzD6UAGnbGB94y7nuX9gs7IOYbh1dlo3PK06l7yT0RbbkrOSfC3Jl5Nc2LUdqZbVlrevId7T3wD+z9g/t2mswwuBg1X12Fjbhq3DZfmyYZ/FWQj8NU/DMPUCkpcCdwLvraofAdcDrwC2AgcYfTWE1Wud5jK8pqrOAy4Brkry2iOMuxH1jWY86oN9I/DZrmmW1uGRHG09x2Jdfgg4DNzaNR0Azqyqc4H3AZ9O8vJjUcsyQ72nx6LuK3juxseGrcMV8mXVUVepZbD1OAuBv6GnYUjyIkZvxq1V9TmAqjpYVc9W1c+BTzL6anqkWqe2DFX1VHd/CLirq+Vg93Vu6SvpoY2qb8wlwINVdbCrd2bWYWeodbaf53a1DFpnt0Pu94A/7L6m03WVPN0N72LUL/7KNWpZbXnXbcD39PuMuiuOX9Y+iO51fx+4faz2DVmHK+XLEV53+p/Fo9kJMY0bo6N9n2C0s2dpx86rj9G8w6jf6z8va980NvzvGfVPArya5+6ceoLRjqmpLAPw68DLxob/F6O+94/x3J0+H+2G38Bzd/p8pX650+fbjHb4nNgNnzTwuvwM8I5ZWYcs20k35DpjdOqQC/jljrJLB6rxYkanEJ9bNt4ccFw3fDbw5Fq1rLa8Pesb7D1l9E1wfKftvxtiHY6txy9v9Dpk9XzZsM/iYH/wfW6M9k5/i9F/3Q8dw/n+E0ZfgR4Cdne3S4H/Dnyja7972Qf9Q12djzK2R3way9B9ML/e3R5eel1GfaD3Ao9190tvfhhdeObxrv75sdd6J6OdaXsZC+aB6vw1Rqe3/rtjbRu2Dhl9lT8A/D9GW0FXDrnOgHlgTzfNn9MdsT5AjXsZ9dUufRZv6Mb9g+79/zrwIPDP16plteXtWd9g72n32f5Kt8yfBV4yxDrs2m8C3r1s3I1Yh6vly4Z9Fj21giQ1Yhb68CVJx4CBL0mNMPAlqREGviQ1wsCXpEYY+JLUCANfkhrx/wEGO5NHyIlGNAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(profits, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then select a value for `alpha` equal to 0.05 as the confidence level for our preferred half-width, defined by `epsilon`. We would like to get the half-width to be 0.1% of our expected profit. This then gives us the desired number of runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean profit: 16703.07856996896 | Half-width (epsilon): 16.70307856996896 | Number of runs (n): 124\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "z = stats.norm.ppf(1-alpha/2)\n",
    "epsilon = 10e-4*np.mean(profits)\n",
    "n = int(np.ceil((z*sigma/epsilon)**2))\n",
    "\n",
    "print(f\"Mean profit: {np.mean(profits)} | Half-width (epsilon): {epsilon} | Number of runs (n): {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see this in some plots. Our preferred half-width (somewhere around 17, decided by the randomness of our initialisation) can be seen to correspond to a number of runs around 120 (again, dependent on random outcomes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikew\\Anaconda3\\envs\\env_gurobi\\lib\\site-packages\\ipykernel_launcher.py:2: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "runs = range(1000)\n",
    "half_widths = [z*sigma/math.sqrt(i) for i in runs]\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(runs, half_widths)\n",
    "plt.xlabel(\"Number of runs\")\n",
    "plt.ylabel(\"half width\")\n",
    "plt.ylim(5, 20)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(runs, half_widths)\n",
    "plt.xlabel(\"Number of runs\")\n",
    "plt.ylabel(\"half width\")\n",
    "plt.xlim(0, 250)\n",
    "plt.ylim(10, 20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that we know our number of runs. To make sure that we have enough runs, we round the number of runs up to the nearest hundred and then find the corresponding confidence interval for the sample mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence interval: (16860.146633946082, 16913.5502697169)\n"
     ]
    }
   ],
   "source": [
    "# Now find profits for this number of runs...\n",
    "n_rounded = int(math.ceil(n / 100.0)) * 100\n",
    "profits = calculate_profits(item_sizes, x, r, pi, num_runs=n_rounded,\n",
    "                            problem_instance=problem_instance)\n",
    "\n",
    "# and find the confidence interval\n",
    "sigma = np.std(profits, ddof=1) * math.sqrt(1/n_rounded)\n",
    "half_width = z*sigma/math.sqrt(n_rounded)\n",
    "confidence_interval = (np.mean(profits) - half_width, np.mean(profits) + half_width)\n",
    "print(\"Confidence interval:\", confidence_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Programming Models\n",
    "## Part 4.\n",
    "\n",
    "In this part, we want to formulate the SKP as a mixed integer linear programming (MILP) problem with an objective of maximising expected profit and of maximising Conditional Value at Risk (CVaR).\n",
    "\n",
    "The model that we use is:\n",
    "\n",
    "\\begin{align*}\n",
    "    \\max_{x, \\varepsilon_u,\\eta, S_u } \\; (1-\\beta) \\left [ \\sum_{u \\in U} P_u \\left ( \\sum_{i=1}^{10} r_i w_{iu} x_i - p \\varepsilon_u \\right ) \\right ] + \\beta \\left [ \\eta - \\frac{1}{1-\\alpha} \\sum_{u \\in U } P_u S_u \\right ]\n",
    "\\end{align*}\n",
    "subject to\n",
    "\\begin{align*}\n",
    "    \\begin{aligned}\n",
    "        x_i & \\in \\{0,1\\} & \\quad & \\text{ for all } i \\in I \\\\\n",
    "        \\varepsilon_u & \\geq 0 & \\quad & \\text{ for all } u \\in U \\\\\n",
    "        \\varepsilon_u & \\geq \\sum_{i=1} ^{10} w_{iu} x_i - K  & \\quad &  \\text{ for all } u \\in U \\\\\n",
    "        S_u & \\geq 0 & \\quad & \\text{ for all } u \\in U \\\\\n",
    "        S_u & \\geq \\eta - \\left ( \\sum_{i=1}^{10} r_i w_{iu} x_i - p \\varepsilon_u \\right ) & \\quad & \\text{ for all } u \\in U.\n",
    "\\end{aligned}\n",
    "\\end{align*}\n",
    "\n",
    "Maximising expected profit corresponds to an objective function with $\\beta = 0$ and maximising Conditional Value at Risk (CVaR) means that $\\beta = 1$ in the objective function. First of all, we need to create all possible scenarios in means of item weights. Since we have 10 items and 2 options for weights for each item, this means that we will have $2^{10} = 1024$ scenarios. These are created in `create_scenarios()`. We also create the function for the scenario weights for the Sample Average Approximation (SAA), seeing as the only difference is how the scenarios and the corresponding probabilities are created. This will also be done in the function `optimise_skp()` already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scenarios(problem_instance):\n",
    "    # Create all possible permutations of 0 and 1\n",
    "    binary_scenarios = [list(i) for i in itertools.product([0, 1], repeat=num_items)]\n",
    "    \n",
    "    # We will, without loss of generality, define that a 1 in binary_scenarios corresponds with a\n",
    "    # high weight and 0 corresponds with a low weight\n",
    "    scenario_weights = [[item_sizes[problem_instance]['dh'][i] if scenario[i] == 1\n",
    "                         else item_sizes[problem_instance]['dl'][i]\n",
    "                         for i in range(num_items)]\n",
    "                        for scenario in binary_scenarios]\n",
    "    scenario_probabilities = [np.prod([pi[i] if scenario[i] == 1 else (1-pi[i])\n",
    "                                       for i in range(num_items)])\n",
    "                              for scenario in binary_scenarios]\n",
    "\n",
    "    return scenario_weights, scenario_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_SAA_weights(item_sizes, pi, problem_instance, N):\n",
    "    scenarios_SAA = [generate_weights(item_sizes, pi, problem_instance) for j in range(N)]\n",
    "\n",
    "    return scenarios_SAA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model formulation using the Gurobi library\n",
    "We are now ready to formulate the linear programming model mentioned above in Gurobi. The entire model is implemented in `optimise_skp()`. Recall that we also implement the SAA model here as well, seeing as the generation of the instances is the only difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimise_skp(problem_instance, beta, alpha, r, p, K, scenario_weights=None,\n",
    "                 scenario_probabilities=None, SAA=False, N=None, verbose=False):\n",
    "\n",
    "    # Generate scenarios for problem instance if not provided\n",
    "    if SAA:\n",
    "        assert N is not None, \"For SAA = True, N should be specified\"\n",
    "\n",
    "        if scenario_weights is None:\n",
    "            scenario_weights = create_SAA_weights(item_sizes, pi, problem_instance, N)\n",
    "\n",
    "        scenario_probabilities = [1/N for j in range(N)]\n",
    "    else:\n",
    "        assert ((scenario_weights is None) and (scenario_probabilities is None)) or \\\n",
    "            ((scenario_weights is not None) and (scenario_probabilities is not None)),\\\n",
    "            \"scenario_weights and scenario_probabilities should both be given or should both be None\"\n",
    "\n",
    "        if (scenario_weights is None) and (scenario_probabilities is None):\n",
    "            scenario_weights, scenario_probabilities = create_scenarios(problem_instance)\n",
    "\n",
    "    # Initialise input parameters\n",
    "    num_items = len(r)\n",
    "    items = range(num_items)\n",
    "    scenarios = range(len(scenario_probabilities))\n",
    "\n",
    "    if beta == 0:\n",
    "        alpha = alpha[\"EV\"]\n",
    "    else:\n",
    "        alpha = alpha[\"CVaR\"]\n",
    "\n",
    "    # Create empty model\n",
    "    m = gb.Model()\n",
    "    \n",
    "    if not verbose:\n",
    "        # Suppress running output\n",
    "        m.setParam('OutputFlag', 0)\n",
    "\n",
    "    # Create variables\n",
    "    x = m.addVars(items, vtype=gb.GRB.BINARY, name=\"x\")\n",
    "    eta = m.addVars(1, vtype=gb.GRB.CONTINUOUS, name=\"eta\")\n",
    "    epsilon = m.addVars(scenarios, vtype=gb.GRB.CONTINUOUS, name=\"epsilon\", lb=0)\n",
    "    s = m.addVars(scenarios, vtype=gb.GRB.CONTINUOUS, name=\"s\", lb=0)\n",
    "\n",
    "    # Set objective function\n",
    "    def scenario_profit(scenario):\n",
    "        return gb.quicksum(r[item]*scenario_weights[scenario][item]*x[item]-p*epsilon[scenario]\n",
    "                           for item in items)\n",
    "\n",
    "    # obj_1 corresponds to the expected profit part of the objective, while obj_2 corresponds to the\n",
    "    # CVaR part\n",
    "    obj_1 = (1-beta)*gb.quicksum(scenario_probabilities[scenario]*scenario_profit(scenario)\n",
    "                                 for scenario in scenarios)\n",
    "    obj_2 = beta*(eta[0]-(1/(1-alpha))*gb.quicksum(scenario_probabilities[scenario]*s[scenario]\n",
    "                                                   for scenario in scenarios))\n",
    "\n",
    "    m.setObjective(obj_1 + obj_2, gb.GRB.MAXIMIZE)\n",
    "\n",
    "    # Set constraints\n",
    "    for scenario in scenarios:\n",
    "        m.addConstr(epsilon[scenario] >= gb.quicksum(scenario_weights[scenario][item]*x[item]\n",
    "                                                     for item in items) - K,\n",
    "                    name=\"epsilon_constraint\")\n",
    "        m.addConstr(s[scenario] >= eta[0] - scenario_profit(scenario), name=\"S_constraint\")\n",
    "\n",
    "    # Solve model\n",
    "    m.optimize()\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5.\n",
    "We now want to solve the EV and CVaR models optimally for 10 random instances created in Part 1 using the model we implemented in `optimise_skp()`. In total, the model will therefore be run $2 \\times 10 = 20$ times, given that we have 10 instances and two models (EV and CVaR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only\n"
     ]
    }
   ],
   "source": [
    "solution_EV = [optimise_skp(instance, beta_model[\"EV\"], alpha_model, r, p, K)\n",
    "               for instance in range(num_instances)]\n",
    "solution_CVaR = [optimise_skp(instance, beta_model[\"CVaR\"], alpha_model, r, p, K)\n",
    "                 for instance in range(num_instances)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having run the models, we print the results below for all 10 instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for instance 1\n",
      "EV Model\n",
      "Maximum objective value: 14629.374682536607\n",
      "x: [0, 0, 0, 1, 0, 0, 0, 1, 1, 1]\n",
      "\n",
      "CVar Model\n",
      "Maximum objective value: 9689.949901109063\n",
      "x: [0, 0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
      "eta: 11661\n",
      "----------\n",
      "Results for instance 2\n",
      "EV Model\n",
      "Maximum objective value: 15339.808183792346\n",
      "x: [0, 0, 0, 0, 0, 1, 0, 1, 1, 1]\n",
      "\n",
      "CVar Model\n",
      "Maximum objective value: 10031.358582811823\n",
      "x: [0, 0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
      "eta: 12107\n",
      "----------\n",
      "Results for instance 3\n",
      "EV Model\n",
      "Maximum objective value: 15039.997476211218\n",
      "x: [0, 0, 0, 0, 0, 1, 0, 1, 1, 1]\n",
      "\n",
      "CVar Model\n",
      "Maximum objective value: 9769.45455698534\n",
      "x: [0, 0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
      "eta: 11899\n",
      "----------\n",
      "Results for instance 4\n",
      "EV Model\n",
      "Maximum objective value: 14310.844199467268\n",
      "x: [0, 0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
      "\n",
      "CVar Model\n",
      "Maximum objective value: 9537.581366271468\n",
      "x: [0, 0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
      "eta: 11531\n",
      "----------\n",
      "Results for instance 5\n",
      "EV Model\n",
      "Maximum objective value: 14983.208156931087\n",
      "x: [0, 0, 0, 0, 0, 1, 0, 1, 1, 1]\n",
      "\n",
      "CVar Model\n",
      "Maximum objective value: 10017.138190795282\n",
      "x: [0, 0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
      "eta: 12067\n",
      "----------\n",
      "Results for instance 6\n",
      "EV Model\n",
      "Maximum objective value: 15165.953109446551\n",
      "x: [0, 0, 0, 0, 1, 0, 1, 1, 1, 0]\n",
      "\n",
      "CVar Model\n",
      "Maximum objective value: 9782.886236389264\n",
      "x: [0, 0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
      "eta: 12022\n",
      "----------\n",
      "Results for instance 7\n",
      "EV Model\n",
      "Maximum objective value: 14800.399643524042\n",
      "x: [0, 0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
      "\n",
      "CVar Model\n",
      "Maximum objective value: 10004.31202581941\n",
      "x: [0, 0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
      "eta: 11965\n",
      "----------\n",
      "Results for instance 8\n",
      "EV Model\n",
      "Maximum objective value: 14883.297388857127\n",
      "x: [0, 0, 0, 0, 0, 1, 0, 1, 1, 1]\n",
      "\n",
      "CVar Model\n",
      "Maximum objective value: 9848.560387322861\n",
      "x: [0, 0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
      "eta: 11937\n",
      "----------\n",
      "Results for instance 9\n",
      "EV Model\n",
      "Maximum objective value: 14315.632511645856\n",
      "x: [0, 0, 0, 0, 0, 1, 0, 1, 1, 1]\n",
      "\n",
      "CVar Model\n",
      "Maximum objective value: 9526.20373012833\n",
      "x: [0, 0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
      "eta: 11573\n",
      "----------\n",
      "Results for instance 10\n",
      "EV Model\n",
      "Maximum objective value: 14637.122332257759\n",
      "x: [0, 0, 0, 0, 1, 0, 1, 1, 1, 0]\n",
      "\n",
      "CVar Model\n",
      "Maximum objective value: 9609.247220716265\n",
      "x: [0, 0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
      "eta: 11579\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# Print the results\n",
    "for j in range(num_instances):\n",
    "    v_EV = solution_EV[j].getVars()\n",
    "    v_CVaR = solution_CVaR[j].getVars()\n",
    "\n",
    "    # Get the values for x and eta in the optimal solutions. For EV, note that eta is always 0, so\n",
    "    # we do not display it.\n",
    "    outcome_x_EV = [int(v_EV[i].x) for i in range(len(v_EV))\n",
    "                    if (re.sub(\"\\[\\d+\\]\", \"\", v_EV[i].varName) == \"x\")]\n",
    "    outcome_x_CVaR = [int(v_CVaR[i].x) for i in range(len(v_CVaR))\n",
    "                      if (re.sub(\"\\[\\d+\\]\", \"\", v_CVaR[i].varName) == \"x\")]\n",
    "    outcome_eta_CVaR = [int(v_CVaR[i].x) for i in range(len(v_CVaR))\n",
    "                        if (re.sub(\"\\[\\d+\\]\", \"\", v_CVaR[i].varName) == \"eta\")][0]\n",
    "\n",
    "    print(\"Results for instance\", j+1)\n",
    "    print(\"EV Model\")\n",
    "    print(\"Maximum objective value:\", solution_EV[j].objVal)\n",
    "    print(\"x:\", outcome_x_EV)\n",
    "    print(\"\")\n",
    "    print(\"CVar Model\")\n",
    "    print(\"Maximum objective value:\", solution_CVaR[j].objVal)\n",
    "    print(\"x:\", outcome_x_CVaR)\n",
    "    print(\"eta:\", outcome_eta_CVaR)\n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-20-98b349c2659b>, line 33)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-20-98b349c2659b>\"\u001b[1;36m, line \u001b[1;32m33\u001b[0m\n\u001b[1;33m    except TypeError:\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# TODO: give these better names, don't overwrite\n",
    "B = K\n",
    "U = p\n",
    "a = 0.95\n",
    "alpha_model = {\"CVaR\": a}\n",
    "profits = np.zeros(10)\n",
    "alphaarr = np.zeros(10)\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    # Solve CVaR mode\n",
    "    model_solves_CVaR = [optimise_skp(instance, beta_model[\"CVaR\"], alpha_model, r, U, B)\n",
    "                         for instance in range(num_instances)]\n",
    "\n",
    "    # TODO: only run for one instance\n",
    "    v_CVaR = model_solves_CVaR[0].getVars()\n",
    "\n",
    "    outcome_x_CVaR = [int(v_CVaR[i].x) for i in range(len(v_CVaR))\n",
    "                      if (re.sub(\"\\[\\d+\\]\", \"\", v_CVaR[i].varName) == \"x\")]\n",
    "    outcome_eta_CVaR = [int(v_CVaR[i].x) for i in range(len(v_CVaR))\n",
    "                        if (re.sub(\"\\[\\d+\\]\", \"\", v_CVaR[i].varName) == \"eta\")]\n",
    "    outcome_epsilon_CVaR = [int(v_CVaR[i].x) for i in range(len(v_CVaR))\n",
    "                            if (re.sub(\"\\[\\d+\\]\", \"\", v_CVaR[i].varName) == \"epsilon\")]\n",
    "    outcome_s_CVaR = [int(v_CVaR[i].x) for i in range(len(v_CVaR))\n",
    "                      if (re.sub(\"\\[\\d+\\]\", \"\", v_CVaR[i].varName) == \"s\")]\n",
    "\n",
    "    print(\"Result for instance\", 1)\n",
    "    print(\"Maximum objective value: \", model_solves_CVaR[0].objVal)\n",
    "    print(\"CVar | x:\", outcome_x_CVaR, \"| eta:\", outcome_eta_CVaR)\n",
    "    print(\"\")\n",
    "\n",
    "    profits[i] = model_solves_CVaR[0].Objval\n",
    "    alphaarr[i] = a\n",
    "\n",
    "a -= .05\n",
    "alpha_model = {\"CVaR\": a}\n",
    "print(profits)\n",
    "print(alphaarr)\n",
    "\n",
    "y = profits\n",
    "x = alphaarr\n",
    "\n",
    "plt.plot(x, y)\n",
    "\n",
    "plt.xlabel('alpha')\n",
    "# naming the y axis\n",
    "plt.ylabel('CVaR')\n",
    "\n",
    "# giving a title to my graph\n",
    "plt.title('Change in CVaR as alpha decreases')\n",
    "plt.xlim(0.95, 0.5)\n",
    "# function to show the plot\n",
    "plt.show()\n",
    "alpha_model = {\"CVaR\": 0.95}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 400+4*g\n",
    "U = math.floor(60 + 0.1 * g)\n",
    "alpha = 0.95\n",
    "profits = np.zeros(30)\n",
    "backsize = np.zeros(30)\n",
    "for i in range(30):\n",
    "\n",
    "    # Solve CVaR mode\n",
    "    model_solves_CVaR = [optimise_skp(instance, beta_model[\"CVaR\"], alpha_model, r, U, B)\n",
    "                         for instance in range(num_instances)]\n",
    "\n",
    "    try:\n",
    "        for j in range(1):\n",
    "            v_CVaR = model_solves_CVaR[j].getVars()\n",
    "\n",
    "            outcome_x_CVaR = [int(v_CVaR[i].x) for i in range(len(v_CVaR))\n",
    "                              if (re.sub(\"\\[\\d+\\]\", \"\", v_CVaR[i].varName) == \"x\")]\n",
    "            outcome_eta_CVaR = [int(v_CVaR[i].x) for i in range(len(v_CVaR))\n",
    "                                if (re.sub(\"\\[\\d+\\]\", \"\", v_CVaR[i].varName) == \"eta\")]\n",
    "            outcome_epsilon_CVaR = [int(v_CVaR[i].x) for i in range(len(v_CVaR))\n",
    "                                    if (re.sub(\"\\[\\d+\\]\", \"\", v_CVaR[i].varName) == \"epsilon\")]\n",
    "            outcome_s_CVaR = [int(v_CVaR[i].x) for i in range(len(v_CVaR))\n",
    "                              if (re.sub(\"\\[\\d+\\]\", \"\", v_CVaR[i].varName) == \"s\")]\n",
    "\n",
    "            print(\"Result for instance\", j+1)\n",
    "            print(\"Maximum objective value: \", model_solves_CVaR[j].Objval)\n",
    "            print(\"CVar | x:\", outcome_x_CVaR, \"| eta:\", outcome_eta_CVaR)\n",
    "            print(\"\")\n",
    "\n",
    "            profits[i] = model_solves_CVaR[j].Objval\n",
    "            backsize[i] = B\n",
    "    except TypeError:\n",
    "        v_CVaR = model_solves_CVaR.getVars()\n",
    "\n",
    "        outcome_x_CVaR = [int(v_CVaR[i].x) for i in range(len(v_CVaR))\n",
    "                          if (re.sub(\"\\[\\d+\\]\", \"\", v_CVaR[i].varName) == \"x\")]\n",
    "        outcome_eta_CVaR = [int(v_CVaR[i].x) for i in range(len(v_CVaR))\n",
    "                            if (re.sub(\"\\[\\d+\\]\", \"\", v_CVaR[i].varName) == \"eta\")]\n",
    "        outcome_epsilon_CVaR = [int(v_CVaR[i].x) for i in range(len(v_CVaR))\n",
    "                                if (re.sub(\"\\[\\d+\\]\", \"\", v_CVaR[i].varName) == \"epsilon\")]\n",
    "        outcome_s_CVaR = [int(v_CVaR[i].x) for i in range(len(v_CVaR))\n",
    "                          if (re.sub(\"\\[\\d+\\]\", \"\", v_CVaR[i].varName) == \"s\")]\n",
    "\n",
    "        print(\"Maximum objective value: \", model_solves_CVaR.Objval)\n",
    "        print(\"CVar | x:\", outcome_x_CVaR, \"| eta:\", outcome_eta_CVaR)\n",
    "        print(statistics.mean(outcome_x_CVaR))\n",
    "\n",
    "    B += 12\n",
    "print(profits)\n",
    "print(backsize)\n",
    "\n",
    "y = profits\n",
    "x = backsize\n",
    "\n",
    "plt.plot(x, y, linestyle='none', marker='o')\n",
    "\n",
    "plt.xlabel('knapsack size')\n",
    "# naming the y axis\n",
    "plt.ylabel('CVaR')\n",
    "\n",
    "# giving a title to my graph\n",
    "plt.title('Change in CVaR as knapsack size increases')\n",
    "\n",
    "# function to show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 400+4*g\n",
    "U = math.floor(60 + 0.1 * g)\n",
    "alpha = 0.95\n",
    "profits = np.zeros(10)\n",
    "penalty = np.zeros(10)\n",
    "for i in range(10):\n",
    "\n",
    "    # Solve CVaR mode\n",
    "    model_solves_CVaR = [optimise_skp(instance, beta_model[\"CVaR\"], alpha_model, r, U, B)\n",
    "                         for instance in range(num_instances)]\n",
    "    \n",
    "    for j in range(1):\n",
    "        v_CVaR = model_solves_CVaR[j].getVars()\n",
    "\n",
    "        outcome_x_CVaR = [int(v_CVaR[i].x) for i in range(len(v_CVaR))\n",
    "                          if (re.sub(\"\\[\\d+\\]\", \"\", v_CVaR[i].varName) == \"x\")]\n",
    "        outcome_eta_CVaR = [int(v_CVaR[i].x) for i in range(len(v_CVaR))\n",
    "                            if (re.sub(\"\\[\\d+\\]\", \"\", v_CVaR[i].varName) == \"eta\")]\n",
    "        outcome_epsilon_CVaR = [int(v_CVaR[i].x) for i in range(len(v_CVaR))\n",
    "                                if (re.sub(\"\\[\\d+\\]\", \"\", v_CVaR[i].varName) == \"epsilon\")]\n",
    "        outcome_s_CVaR = [int(v_CVaR[i].x) for i in range(len(v_CVaR))\n",
    "                          if (re.sub(\"\\[\\d+\\]\", \"\", v_CVaR[i].varName) == \"s\")]\n",
    "\n",
    "        print(\"Result for instance\", j+1)\n",
    "        print(\"Maximum objective value: \", model_solves_CVaR[j].Objval)\n",
    "        print(\"CVar | x:\", outcome_x_CVaR, \"| eta:\", outcome_eta_CVaR)\n",
    "        print(\"\")\n",
    "\n",
    "        profits[i] = model_solves_CVaR[j].Objval\n",
    "        penalty[i] = U\n",
    "\n",
    "    U -= 5\n",
    "print(profits)\n",
    "print(penalty)\n",
    "\n",
    "y = profits\n",
    "x = penalty\n",
    "\n",
    "plt.plot(x, y)\n",
    "\n",
    "plt.xlabel('penalty')\n",
    "# naming the y axis\n",
    "plt.ylabel('CVaR')\n",
    "\n",
    "# giving a title to my graph\n",
    "plt.title('Change in CVaR as penalty decreases')\n",
    "plt.xlim(60, 15)\n",
    "# function to show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Average Approximation\n",
    "## Part 7.\n",
    "\n",
    "The Sample Average Approximation (SAA) model is given by:\n",
    "\\begin{align*}\n",
    "    \\max_{x, \\varepsilon_u, \\eta, S_u} \\; (1-\\beta)\\left[\\frac{1}{N} \\sum_{u=1}^N \\left ( \\sum_{i=1}^{10} r_i W^{u}_i x_i - p \\varepsilon_u \\right)\\right] + \\beta\\left[\\eta - \\frac{1}{(1-\\alpha)N} \\sum_{u=1 }^N S_u \\right] \\tag{SAA}\n",
    "    \\end{align*}\n",
    "subject to \n",
    "    \\begin{align*}\n",
    "    \\begin{aligned}\n",
    "     x_i & \\in \\{0,1\\} & \\quad & \\text{ for all } i \\in I \\\\\n",
    "     \\varepsilon_u & \\geq 0 & \\quad & \\text{ for all } u \\in U \\\\\n",
    "    \\varepsilon_u & \\geq \\sum_{i=1} ^{10} W^{u}_i x_i - K  & \\quad &  \\text{ for all } u \\in U \\\\\n",
    "    S_u & \\geq 0 & \\quad & \\text{ for all } u \\in U \\\\\n",
    "    S_u & \\geq \\eta - \\left ( \\sum_{i=1}^{10} r_i W^{u}_i x_i - p \\varepsilon_u \\right ) & \\quad & \\text{ for all } u \\in U.\n",
    "    \\end{aligned}\n",
    "\\end{align*}\n",
    "\n",
    "For the first problem instance, we want to solve the SAA model $M$ times given a sample of size $N$ to obtain the SAA solution, which is the solution corresponding to the maximum out of $M$ optimal values. A relatively small number for $M$ is usually fine, we take $M = 10$. A larger number for $N$ can be taken. We take $N = 1000$ in the interest of running time, but a larger value for $N$ could be chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "M = 10\n",
    "problem_instance = 0\n",
    "\n",
    "SAA_solution_EV = [optimise_skp(problem_instance, beta_model[\"EV\"], alpha_model, r, p, K,\n",
    "                                SAA=True, N=N) for j in range(M)]\n",
    "SAA_solution_CVaR = [optimise_skp(problem_instance, beta_model[\"CVaR\"], alpha_model, r, p, K,\n",
    "                                  SAA=True, N=N) for j in range(M)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now find the optimal solution by iterating over all $M$ runs and retaining the best solution for both the EV and CVaR model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EV Model\n",
      "Maximum objective value: 14708.936063947607\n",
      "x: [0, 0, 0, 1, 0, 0, 0, 1, 1, 1]\n",
      "\n",
      "CVaR Model\n",
      "Maximum objective value: 10185.557585454682\n",
      "x: [0, 0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
      "eta: 11661\n"
     ]
    }
   ],
   "source": [
    "SAA_objective_values_EV = []\n",
    "SAA_objective_values_CVaR = []\n",
    "maximum_objective_EV = 0\n",
    "maximum_objective_CVaR = 0\n",
    "\n",
    "for j in range(M):\n",
    "    # EV\n",
    "    SAA_objective_values_EV.append(SAA_solution_EV[j].objVal)\n",
    "\n",
    "    if(SAA_solution_EV[j].objVal > maximum_objective_EV):\n",
    "        maximum_objective_EV = SAA_solution_EV[j].objVal\n",
    "        v_EV = SAA_solution_EV[j].getVars()\n",
    "        SAA_x_EV = [int(v_EV[i].x) for i in range(len(v_EV))\n",
    "                    if (re.sub(\"\\[\\d+\\]\", \"\", v_EV[i].varName) == \"x\")]\n",
    "\n",
    "    # CVaR\n",
    "    SAA_objective_values_CVaR.append(SAA_solution_CVaR[j].objVal)\n",
    "\n",
    "    if(SAA_solution_CVaR[j].objVal > maximum_objective_CVaR):\n",
    "        maximum_objective_CVaR = SAA_solution_CVaR[j].objVal\n",
    "        v_CVaR = SAA_solution_CVaR[j].getVars()\n",
    "        SAA_x_CVaR = [int(v_CVaR[i].x) for i in range(len(v_CVaR))\n",
    "                      if (re.sub(\"\\[\\d+\\]\", \"\", v_CVaR[i].varName) == \"x\")]\n",
    "        SAA_eta_CVaR = [int(v_CVaR[i].x) for i in range(len(v_CVaR))\n",
    "                        if (re.sub(\"\\[\\d+\\]\", \"\", v_CVaR[i].varName) == \"eta\")][0]\n",
    "        \n",
    "print(\"EV Model\")\n",
    "print(\"Maximum objective value:\", maximum_objective_EV)\n",
    "print(\"x:\", SAA_x_EV)\n",
    "print(\"\")\n",
    "print(\"CVaR Model\")\n",
    "print(\"Maximum objective value:\", maximum_objective_CVaR)\n",
    "print(\"x:\", SAA_x_CVaR)\n",
    "print(\"eta:\", SAA_eta_CVaR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivation of optimality gap\n",
    "The optimality gap is defined by: \n",
    "\\begin{align*}\n",
    "    \\mathrm{gap}(\\hat{x}) =  v^* - g(\\hat{x}),\n",
    "\\end{align*}\n",
    "    \n",
    "An upper bound for $v^*$ is found using $E(\\hat{v}_N)$. For this we need the sample mean of $E(\\hat{v}_N)$:\n",
    "\\begin{align*}\n",
    "    \\bar{v}_{N,M} = \\frac{1}{M} \\sum_{j = 1}^M \\hat{v}^j_N\n",
    "\\end{align*}\n",
    "    \n",
    "and the sample variance: \n",
    "\\begin{align*}\n",
    "    \\hat{\\sigma}^2_{N,M} = \\frac{1}{M(M-1)} \\sum_{j =1}^M \\left(\\hat{v}^j_N - \\bar{v}_{N,M}\\right)^2.\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EV Model\n",
      "Sample mean: 14620.615853797985\n",
      "Standard deviation of sample mean: 18.719040638778658\n",
      "\n",
      "CVaR Model\n",
      "Sample mean: 9736.300306804356\n",
      "Standard deviation of sample mean: 125.47468936280656\n"
     ]
    }
   ],
   "source": [
    "# Sample mean\n",
    "sample_mean_UB_EV = np.mean(SAA_objective_values_EV)\n",
    "sample_mean_UB_CVaR = np.mean(SAA_objective_values_CVaR)\n",
    "\n",
    "# Sample standard deviation\n",
    "sample_std_UB_EV = np.std(SAA_objective_values_EV, ddof=1) * math.sqrt(1/M)\n",
    "sample_std_UB_CVaR = np.std(SAA_objective_values_CVaR, ddof=1) * math.sqrt(1/M)\n",
    "\n",
    "print(\"EV Model\")\n",
    "print(f\"Sample mean: {sample_mean_UB_EV}\")\n",
    "print(f\"Standard deviation of sample mean: {sample_std_UB_EV}\")\n",
    "print(\"\")\n",
    "print(\"CVaR Model\")\n",
    "print(f\"Sample mean: {sample_mean_UB_CVaR}\")\n",
    "print(f\"Standard deviation of sample mean: {sample_std_UB_CVaR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 95% upper bound for $v^*$ is then given by:\n",
    "$$\n",
    "\\begin{align*}\n",
    "    U_{N,M} = \\bar{v}_{N,M} + t_{\\gamma,\\nu}\\hat{\\sigma}_{N,M},\n",
    "\\end{align*}\n",
    "$$\n",
    "where $\\nu = M-1$ and $t_{\\gamma,\\nu}$ is the $\\gamma$-critical value of the $t$-distribution with $\\nu$ degrees of freedom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.0% upper bound (EV model): 14654.9299692798\n",
      "95.0% upper bound (CVaR model): 9966.309582596014\n"
     ]
    }
   ],
   "source": [
    "nu = M-1\n",
    "gamma = 0.05\n",
    "critical_value_t = stats.t.ppf(1-gamma, nu)\n",
    "\n",
    "gap_UB_EV = sample_mean_UB_EV + critical_value_t*sample_std_UB_EV\n",
    "gap_UB_CVaR = sample_mean_UB_CVaR + critical_value_t*sample_std_UB_CVaR\n",
    "\n",
    "print(f\"{100*(1-gamma)}% upper bound (EV model): {gap_UB_EV}\")\n",
    "print(f\"{100*(1-gamma)}% upper bound (CVaR model): {gap_UB_CVaR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the lower bound for $g(\\hat{x})$, we first need to generate a random sample $W^1, W^2, \\dots, W^{N'}$, where $N'$ is some large number. The calculations are quite quick as they only concern function evaluations, so we are free to take a relatively large number. We take $N' = 10^5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_prime = 10000\n",
    "scenario_weights_SAA = create_SAA_weights(item_sizes, pi, problem_instance, N_prime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we compute the sample mean $\\hat{g}_{N'}(\\hat{x})$ and its sample variance.\n",
    "\n",
    "Let \n",
    "$$\n",
    "\\begin{align*}\n",
    "    Q(\\hat{x},W^{u}) = (1-\\beta) \\left(\\sum_{i=1}^{10} r_i W^{u}_i \\hat{x}_i - p \\varepsilon_u \\right) + \\beta \\left[\\eta - \\frac{1}{1-\\alpha} S_u \\right],\n",
    "\\end{align*}\n",
    "$$\n",
    "where $\\varepsilon_u = \\max \\left\\{0, \\sum_{i=1} ^{10} W^{u}_i \\hat{x}_i - K \\right\\}$ and $S_u = \\max \\left\\{0,\\eta - \\left(\\sum_{i=1}^{10} r_i W^{u}_i \\hat{x}_i - p \\varepsilon_u \\right) \\right\\}$ for all $u \\in U$. This function is coded in `scenario_profit_given_x_hat`.\n",
    "\n",
    "Then, the sample average is given by\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\hat{g}_{N'}(\\hat{x}) = \\frac{1}{N'} \\sum_{u=1 }^{N'}  Q(\\hat{x},W^{u}),\n",
    "\\end{align*}\n",
    "$$\n",
    "and the sample variance of $\\hat{g}_{N'}(\\hat{x})$ is given by\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\hat{\\sigma}^2_{N'}(\\hat{x}) = \\frac{1}{N'(N'-1)} \\sum_{u=1}^{N'} \\left[Q(\\hat{x},W^{u}) - \\hat{g}_{N'}(\\hat{x}) \\right]^2.\n",
    "\\end{align*}\n",
    "$$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scenario_profit_given_x_hat(x, alpha, beta, r, p, K, eta, scenario_weight):\n",
    "    \n",
    "    scenario_excess = max(0, sum(scenario_weight*x) - K)\n",
    "    profit_EV = sum(r*scenario_weight*x) - p*scenario_excess   \n",
    "    profit_CVaR = eta-(1/(1-alpha))*max(0, eta-profit_EV)\n",
    "    \n",
    "    Q = (1-beta)*profit_EV + beta*profit_CVaR\n",
    "    \n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LB_scenarios = range(len(scenario_weights_SAA))\n",
    "\n",
    "Q_EV = [scenario_profit_given_x_hat(SAA_x_EV, alpha_model[\"EV\"], beta_model[\"EV\"], r, p, K,\n",
    "                                    SAA_eta_CVaR, scenario_weights_SAA[scenario])\n",
    "        for scenario in LB_scenarios]\n",
    "Q_CVaR = [scenario_profit_given_x_hat(SAA_x_CVaR, alpha_model[\"CVaR\"], beta_model[\"CVaR\"], r, p, K,\n",
    "                                      SAA_eta_CVaR, scenario_weights_SAA[scenario])\n",
    "          for scenario in LB_scenarios]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EV Model\n",
      "Sample mean: 14609.960450480083\n",
      "Standard deviation of sample mean: 26.376770314491782\n",
      "\n",
      "CVaR Model\n",
      "Sample mean: 9713.84961756664\n",
      "Standard deviation of sample mean: 119.77388120678549\n"
     ]
    }
   ],
   "source": [
    "# Sample mean\n",
    "sample_mean_LB_EV = np.mean(Q_EV)\n",
    "sample_mean_LB_CVaR = np.mean(Q_CVaR)\n",
    "\n",
    "# Sample standard deviation\n",
    "sample_std_LB_EV = np.std(Q_EV, ddof=1) * math.sqrt(1/N_prime)\n",
    "sample_std_LB_CVaR = np.std(Q_CVaR, ddof=1) * math.sqrt(1/N_prime)\n",
    "\n",
    "print(\"EV Model\")\n",
    "print(f\"Sample mean: {sample_mean_LB_EV}\")\n",
    "print(f\"Standard deviation of sample mean: {sample_std_LB_EV}\")\n",
    "print(\"\")\n",
    "print(\"CVaR Model\")\n",
    "print(f\"Sample mean: {sample_mean_LB_CVaR}\")\n",
    "print(f\"Standard deviation of sample mean: {sample_std_LB_CVaR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 95% lower bound for $g(\\hat{x})$ is then given by:\n",
    "$$\n",
    "\\begin{align*}\n",
    "    L_{N'} = \\hat{g}_{N'}(\\hat{x}) - z_{\\gamma} \\hat{\\sigma}_{N'}(\\hat{x}),\n",
    "\\end{align*}\n",
    "$$\n",
    "where $z_{\\gamma}$ is the $\\gamma$-critical value of the standard normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.0% lower bound (EV model): 14566.574524161026\n",
      "95.0% lower bound (CVaR model): 9516.839114649605\n"
     ]
    }
   ],
   "source": [
    "critical_value_z = stats.norm.ppf(1-gamma,0,1)\n",
    "gap_LB_EV = sample_mean_LB_EV - critical_value_z*sample_std_LB_EV\n",
    "gap_LB_CVaR = sample_mean_LB_CVaR - critical_value_z*sample_std_LB_CVaR\n",
    "\n",
    "print(f\"{100*(1-gamma)}% lower bound (EV model): {gap_LB_EV}\")\n",
    "print(f\"{100*(1-gamma)}% lower bound (CVaR model): {gap_LB_CVaR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a total 90% confidence bound on the true $\\mathrm{gap}(\\hat{x})$:\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\widehat{gap}(\\hat{x}) = U_{N,M} - L_{N'}.\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.0% confidence bound on true gap (EV model): 88.35544511877379\n",
      "90.0% confidence bound on true gap (CVaR model): 449.47046794640846\n"
     ]
    }
   ],
   "source": [
    "gap_EV = gap_UB_EV - gap_LB_EV\n",
    "gap_CVaR = gap_UB_CVaR - gap_LB_CVaR\n",
    "\n",
    "print(f\"{100*(1-2*gamma)}% confidence bound on true gap (EV model): {gap_EV}\")\n",
    "print(f\"{100*(1-2*gamma)}% confidence bound on true gap (CVaR model): {gap_CVaR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus question\n",
    "We now research how antithetic variates can be adopted within the SAA scheme. We start by generating two random sample batches of the weights $W^1, \\dots, W^N$ using $U$ and $1-U$, where $U \\sim Unif(0,1)$ of size $N$. This is done in `create_SAA_weights_AV()`, using `generate_weights_AV()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_weights_AV(pi, item_sizes, problem_instance):\n",
    "    \n",
    "    num_items = len(pi)\n",
    "    \n",
    "    U = np.random.uniform(size=num_items)\n",
    "    W1 = [item_sizes[problem_instance][\"dh\"][i] if U[i] < pi[i]\n",
    "          else item_sizes[problem_instance][\"dl\"][i] for i in range(num_items)]\n",
    "    W1 = np.asarray(W1)\n",
    "\n",
    "    U_anti = 1-U\n",
    "    W2 = [item_sizes[problem_instance][\"dh\"][i] if U_anti[i] < pi[i]\n",
    "          else item_sizes[problem_instance][\"dl\"][i] for i in range(num_items)]\n",
    "    W2 = np.asarray(W2)\n",
    "\n",
    "    weights_AV = (W1, W2)\n",
    "    \n",
    "    return weights_AV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_SAA_weights_AV(pi, item_sizes, problem_instance, N):\n",
    "\n",
    "    scenarios_SAA_AV_1 = []\n",
    "    scenarios_SAA_AV_2 = []\n",
    "\n",
    "    for j in range(N):\n",
    "        W = generate_weights_AV(pi, item_sizes, problem_instance)\n",
    "        scenarios_SAA_AV_1.append(W[0])\n",
    "        scenarios_SAA_AV_2.append(W[1])\n",
    "        \n",
    "    scenarios_SAA_AV = (scenarios_SAA_AV_1, scenarios_SAA_AV_2)\n",
    "    \n",
    "    return scenarios_SAA_AV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now solve the SAA scheme $M$ times again, but now for the antithetic variates. We get pairs of antithetic variates $(\\hat{v}^{1,1}_N,\\hat{v}^{1,2}_N), (\\hat{v}^{2,1}_N,\\hat{v}^{2,2}_N), \\dots, (\\hat{v}^{M,1}_N,\\hat{v}^{M,2}_N)$ and then determine $\\hat{v}^{j}_N = \\frac{1}{2}\\left(\\hat{v}^{j,1}_N+\\hat{v}^{j,2}_N\\right)$ for all $j=1,\\dots,M$ and get the SAA solution $\\hat{x}$ in a similar sense as described before.\n",
    "\n",
    "Since we now have the antithetic variates, we take $M$ and $N'$ half as large as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "M //= 2\n",
    "\n",
    "SAA_solution_EV_AV = []\n",
    "SAA_solution_CVaR_AV = []\n",
    "SAA_EV_max_objective = 0\n",
    "SAA_CVaR_max_objective = 0\n",
    "\n",
    "for j in range(M):\n",
    "    # Solve EV model\n",
    "    scenario_weights_AV = create_SAA_weights_AV(pi, item_sizes, problem_instance, N)\n",
    "\n",
    "    sol1 = optimise_skp(problem_instance, beta_model[\"EV\"], alpha_model, r, p, K,\n",
    "                        scenario_weights=scenario_weights_AV[0], scenario_probabilities=None,\n",
    "                        SAA=True, N=N)\n",
    "    sol2 = optimise_skp(problem_instance, beta_model[\"EV\"], alpha_model, r, p, K,\n",
    "                        scenario_weights=scenario_weights_AV[1], scenario_probabilities=None,\n",
    "                        SAA=True, N=N)\n",
    "\n",
    "    if(sol1.objVal > SAA_EV_max_objective):\n",
    "        SAA_EV_max_objective = sol1.objVal\n",
    "        EV_AV = sol1.getVars()\n",
    "        SAA_x_EV_AV = [int(EV_AV[i].x) for i in range(len(EV_AV))\n",
    "                       if (re.sub(\"\\[\\d+\\]\", \"\", EV_AV[i].varName) == \"x\")]\n",
    "\n",
    "    if(sol2.objVal > SAA_EV_max_objective):\n",
    "        SAA_EV_max_objective = sol2.objVal\n",
    "        EV_AV = sol2.getVars()\n",
    "        SAA_x_EV_AV = [int(EV_AV[i].x) for i in range(len(EV_AV))\n",
    "                       if (re.sub(\"\\[\\d+\\]\", \"\", EV_AV[i].varName) == \"x\")]\n",
    "\n",
    "    SAA_solution_EV_AV.append((sol1.objVal+sol2.objVal)/2)\n",
    "\n",
    "    # Solve CVaR model\n",
    "    scenario_weights_AV = create_SAA_weights_AV(pi, item_sizes, problem_instance, N)\n",
    "\n",
    "    sol1 = optimise_skp(problem_instance, beta_model[\"CVaR\"], alpha_model, r, p, K,\n",
    "                               scenario_weights=scenario_weights_AV[0], scenario_probabilities=None,\n",
    "                               SAA=True, N=N)\n",
    "    sol2 = optimise_skp(problem_instance, beta_model[\"CVaR\"], alpha_model, r, p, K,\n",
    "                               scenario_weights=scenario_weights_AV[1], scenario_probabilities=None,\n",
    "                               SAA=True, N=N)\n",
    "\n",
    "    if(sol1.objVal > SAA_CVaR_max_objective):\n",
    "        SAA_CVaR_max_objective = sol1.objVal\n",
    "        CVaR_AV = sol1.getVars()\n",
    "        SAA_x_CVaR_AV = [int(CVaR_AV[i].x) for i in range(len(CVaR_AV))\n",
    "                         if (re.sub(\"\\[\\d+\\]\", \"\", CVaR_AV[i].varName) == \"x\")]\n",
    "        SAA_eta_CVaR_AV = [int(CVaR_AV[i].x) for i in range(len(CVaR_AV))\n",
    "                           if (re.sub(\"\\[\\d+\\]\", \"\", CVaR_AV[i].varName) == \"eta\")][0]\n",
    "\n",
    "    if(sol2.objVal > SAA_CVaR_max_objective):\n",
    "        SAA_CVaR_max_objective = sol2.objVal\n",
    "        CVaR_AV = sol2.getVars()\n",
    "        SAA_x_CVaR_AV = [int(CVaR_AV[i].x) for i in range(len(CVaR_AV))\n",
    "                         if (re.sub(\"\\[\\d+\\]\", \"\", CVaR_AV[i].varName) == \"x\")]\n",
    "        SAA_eta_CVaR_AV = [int(CVaR_AV[i].x) for i in range(len(CVaR_AV))\n",
    "                           if (re.sub(\"\\[\\d+\\]\", \"\", CVaR_AV[i].varName) == \"eta\")][0]\n",
    "\n",
    "    SAA_solution_CVaR_AV.append((sol1.objVal+sol2.objVal)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EV model: \n",
      "x: [0, 0, 0, 1, 0, 0, 0, 1, 1, 1]\n",
      "Maximum objective value: 14704.086510998064\n",
      "\n",
      "Sample mean with AV:  14643.216077369256\n",
      "Standard deviation of sample mean with AV:  11.588871611596696\n",
      "\n",
      "Sample mean without AV:  14620.615853797985\n",
      "Standard deviation of sample mean without AV:  18.719040638778658\n",
      "--------------------\n",
      "CVaR model: \n",
      "x: [0, 0, 0, 0, 0, 1, 0, 1, 1, 1]\n",
      "eta: 11832\n",
      "Maximum objective value: 10183.918190350096\n",
      "\n",
      "Sample mean with AV:  9600.131876382391\n",
      "Standard deviation of sample mean with AV:  105.07925752606984\n",
      "\n",
      "Sample mean without AV:  9736.300306804356\n",
      "Standard deviation of sample mean without AV:  125.47468936280656\n"
     ]
    }
   ],
   "source": [
    "# Sample mean\n",
    "sample_mean_UB_EV_AV = np.mean(SAA_solution_EV_AV)\n",
    "sample_mean_UB_CVaR_AV = np.mean(SAA_solution_CVaR_AV)\n",
    "\n",
    "# Sample standard deviation\n",
    "sample_std_UB_EV_AV = np.std(SAA_solution_EV_AV, ddof=1) * math.sqrt(1/M)\n",
    "sample_std_UB_CVaR_AV = np.std(SAA_solution_CVaR_AV, ddof=1) * math.sqrt(1/M)\n",
    "\n",
    "# SAA solution EV model\n",
    "print(\"EV model: \")\n",
    "print(\"x:\", SAA_x_EV_AV)\n",
    "print(\"Maximum objective value:\", SAA_EV_max_objective)\n",
    "print(\"\")\n",
    "print(\"Sample mean with AV: \", sample_mean_UB_EV_AV)\n",
    "print(\"Standard deviation of sample mean with AV: \", sample_std_UB_EV_AV)\n",
    "print(\"\")\n",
    "print(\"Sample mean without AV: \", sample_mean_UB_EV)\n",
    "print(\"Standard deviation of sample mean without AV: \", sample_std_UB_EV)\n",
    "print(\"--------------------\")\n",
    "print(\"CVaR model: \")\n",
    "print(\"x:\", SAA_x_CVaR_AV)\n",
    "print(\"eta:\", SAA_eta_CVaR_AV)\n",
    "print(\"Maximum objective value:\", SAA_CVaR_max_objective)\n",
    "print(\"\")\n",
    "print(\"Sample mean with AV: \", sample_mean_UB_CVaR_AV)\n",
    "print(\"Standard deviation of sample mean with AV: \", sample_std_UB_CVaR_AV)\n",
    "print(\"\")\n",
    "print(\"Sample mean without AV: \", sample_mean_UB_CVaR)\n",
    "print(\"Standard deviation of sample mean without AV: \", sample_std_UB_CVaR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now repeat the process and generate two random sample batches of the weights $W^1,\\dots,W^{N'}$ using $U$ and $1-U$ and obtain $Q_1\\left(\\hat{x},W^1\\right), \\dots, Q_1\\left(\\hat{x},W^{N'}\\right)$ and $Q_2\\left(\\hat{x},W^1\\right), \\dots, Q_2\\left(\\hat{x},W^{N'}\\right)$. Then, we compute $Q\\left(\\hat{x},W^u\\right) = \\frac{1}{2}\\left(Q_1\\left(\\hat{x},W^u\\right) + Q_2\\left(\\hat{x},W^u\\right)\\right)$ for all $u = 1, \\dots, N'$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_prime //= 2\n",
    "scenario_weights_SAA_AV = create_SAA_weights_AV(pi, item_sizes, problem_instance, N_prime)\n",
    "\n",
    "LB_scenarios_AV = range(len(scenario_weights_SAA_AV[0]))\n",
    "\n",
    "# Find Q for EV Model\n",
    "Q_EV_AV_1 = [scenario_profit_given_x_hat(SAA_x_EV_AV, alpha_model[\"EV\"], beta_model[\"EV\"], r, p, K,\n",
    "                                         SAA_eta_CVaR_AV, scenario_weights_SAA_AV[0][scenario])\n",
    "             for scenario in LB_scenarios_AV]\n",
    "Q_EV_AV_2 = [scenario_profit_given_x_hat(SAA_x_EV_AV, alpha_model[\"EV\"], beta_model[\"EV\"], r, p, K,\n",
    "                                         SAA_eta_CVaR_AV, scenario_weights_SAA_AV[1][scenario])\n",
    "             for scenario in LB_scenarios_AV]\n",
    "Q_EV_AV = (np.array(Q_EV_AV_1) + np.array(Q_EV_AV_2)) / 2\n",
    "\n",
    "# Find Q for CVaR Model\n",
    "Q_CVaR_AV_1 = [scenario_profit_given_x_hat(SAA_x_CVaR_AV, 0.95, beta_model[\"CVaR\"], r, p, K,\n",
    "                                           SAA_eta_CVaR_AV, scenario_weights_SAA_AV[0][scenario])\n",
    "               for scenario in LB_scenarios_AV]\n",
    "Q_CVaR_AV_2 = [scenario_profit_given_x_hat(SAA_x_CVaR_AV, 0.95, beta_model[\"CVaR\"], r, p, K,\n",
    "                                           SAA_eta_CVaR_AV, scenario_weights_SAA_AV[1][scenario])\n",
    "               for scenario in LB_scenarios_AV]\n",
    "Q_CVaR_AV = (np.array(Q_CVaR_AV_1) + np.array(Q_CVaR_AV_2)) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EV Model\n",
      "Sample mean with AV: 14650.620805837918\n",
      "Standard deviation of sample mean with AV: 21.632271088393786\n",
      "\n",
      "Sample mean without AV: 14609.960450480083\n",
      "Standard deviation of sample mean without AV: 26.376770314491782\n",
      "--------------------\n",
      "CVaR Model\n",
      "Sample mean with AV: 9269.389543083915\n",
      "Standard deviation of sample mean with AV: 136.96000022320794\n",
      "\n",
      "Sample mean without AV: 9713.84961756664\n",
      "Standard deviation of sample mean without AV: 119.77388120678549\n"
     ]
    }
   ],
   "source": [
    "# Sample mean\n",
    "sample_mean_LB_EV_AV = np.mean(Q_EV_AV)\n",
    "sample_mean_LB_CVaR_AV = np.mean(Q_CVaR_AV)\n",
    "\n",
    "# Sample standard deviation\n",
    "sample_std_LB_EV_AV = np.std(Q_EV_AV, ddof=1) * math.sqrt(1/N_prime)\n",
    "sample_std_LB_CVaR_AV = np.std(Q_CVaR_AV, ddof=1) * math.sqrt(1/N_prime)\n",
    "\n",
    "print(\"EV Model\")\n",
    "print(\"Sample mean with AV:\", sample_mean_LB_EV_AV)\n",
    "print(\"Standard deviation of sample mean with AV:\", sample_std_LB_EV_AV)\n",
    "print(\"\")\n",
    "print(\"Sample mean without AV:\", sample_mean_LB_EV)\n",
    "print(\"Standard deviation of sample mean without AV:\", sample_std_LB_EV)\n",
    "print(\"--------------------\")\n",
    "print(\"CVaR Model\")\n",
    "print(\"Sample mean with AV:\", sample_mean_LB_CVaR_AV)\n",
    "print(\"Standard deviation of sample mean with AV:\", sample_std_LB_CVaR_AV)\n",
    "print(\"\")\n",
    "print(\"Sample mean without AV:\", sample_mean_LB_CVaR)\n",
    "print(\"Standard deviation of sample mean without AV:\", sample_std_LB_CVaR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we determine a $90\\%$ confidence bound on the true $\\mathrm{gap}(\\hat{x})$ using antithetic variates. The gap is given by\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\widehat{gap}(\\hat{x}) = U_{N,M} - L_{N'},\n",
    "\\end{align*}\n",
    "$$\n",
    "with the upper and lower bounds defined similarly as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.0% confidence bound on true gap (EV model) without AV: 88.35544511877379\n",
      "90.0% confidence bound on true gap (EV model) with AV: 52.8828897347812\n",
      "\n",
      "90.0% confidence bound on true gap (CVaR model) with AV: 449.47046794640846\n",
      "90.0% confidence bound on true gap (CVaR model) with AV: 748.6436323375747\n"
     ]
    }
   ],
   "source": [
    "nu = M-1\n",
    "gamma = 0.05\n",
    "\n",
    "# Upper bound\n",
    "critical_value_t_AV = stats.t.ppf(1-gamma,nu)\n",
    "gap_UB_EV_AV = sample_mean_UB_EV_AV + critical_value_t_AV*sample_std_UB_EV_AV\n",
    "gap_UB_CVaR_AV = sample_mean_UB_CVaR_AV + critical_value_t*sample_std_UB_CVaR_AV\n",
    "\n",
    "# Lower bound\n",
    "critical_value_z_AV = stats.norm.ppf(1-gamma,0,1)\n",
    "gap_LB_EV_AV = sample_mean_LB_EV_AV - critical_value_z_AV*sample_std_LB_EV_AV\n",
    "gap_LB_CVaR_AV = sample_mean_LB_CVaR_AV - critical_value_z*sample_std_LB_CVaR_AV\n",
    "\n",
    "# Gap \n",
    "gap_EV_AV = gap_UB_EV_AV - gap_LB_EV_AV\n",
    "gap_CVaR_AV = gap_UB_CVaR_AV - gap_LB_CVaR_AV\n",
    "\n",
    "print(f\"{100*(1-2*gamma)}% confidence bound on true gap (EV model) without AV: {gap_EV}\")\n",
    "print(f\"{100*(1-2*gamma)}% confidence bound on true gap (EV model) with AV: {gap_EV_AV}\")\n",
    "print(\"\")\n",
    "print(f\"{100*(1-2*gamma)}% confidence bound on true gap (CVaR model) with AV: {gap_CVaR}\")\n",
    "print(f\"{100*(1-2*gamma)}% confidence bound on true gap (CVaR model) with AV: {gap_CVaR_AV}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
